{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kdhaw6/Deep_Learning_E-Commerce-Customer-Satisfaction-CSAT-Model-/blob/main/E_Commerce_Customer_Satisfaction_Score_Prediction_KD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILM16xV1PD8m"
      },
      "source": [
        "# **Project Name**    -  **E-Commerce Customer Satisfaction Score Prediction**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqVZBxrvPD8n"
      },
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaldy8SH6Dl"
      },
      "source": [
        "# **Problem Statement**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jivUA-ONOwse"
      },
      "source": [
        "**BUSINESS PROBLEM OVERVIEW**\n",
        "\n",
        "\n",
        "Customer satisfaction in the e-commerce sector is a pivotal metric that influences loyalty, repeat business, and word-of-mouth marketing. Traditionally, companies have relied on direct surveys to gauge customer satisfaction, which can be time-consuming and may not always capture the full spectrum of customer experiences. With the advent of deep learning, it's now possible to predict customer satisfaction scores in real-time, offering a granular view of service performance and identifying areas for immediate improvement.\n",
        "\n",
        "**Project Goal**\n",
        "\n",
        "The primary goal of this project is to develop a deep learning model that can accurately predict the CSAT scores based on customer interactions and feedback. By doing so, we aim to provide e-commerce businesses with a powerful tool to monitor and enhance customer satisfaction in real-time, thereby improving service quality and fostering customer loyalty."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_i_v8NEhb9l"
      },
      "source": [
        "# ***Let's Begin !***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfV-JJviCcP"
      },
      "source": [
        "## ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lxredqlCYt"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:48.921967Z",
          "iopub.status.busy": "2024-06-03T03:41:48.921035Z",
          "iopub.status.idle": "2024-06-03T03:41:51.126487Z",
          "shell.execute_reply": "2024-06-03T03:41:51.125582Z",
          "shell.execute_reply.started": "2024-06-03T03:41:48.921934Z"
        },
        "id": "M8Vqi-pPk-HR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "# Data manipulation and visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine learning and ANN building\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EtDOJK0hJwSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:51.129575Z",
          "iopub.status.busy": "2024-06-03T03:41:51.128623Z",
          "iopub.status.idle": "2024-06-03T03:41:51.882093Z",
          "shell.execute_reply": "2024-06-03T03:41:51.881251Z",
          "shell.execute_reply.started": "2024-06-03T03:41:51.129541Z"
        },
        "id": "FQ9iULLgVgv0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Loading E-Commerce Dataset in pandas dataframe\n",
        "dataset=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Msc Projects/M4 - Deep Learning - CSAT/eCommerce_Customer_support_data.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x71ZqKXriCWQ"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:51.883722Z",
          "iopub.status.busy": "2024-06-03T03:41:51.883325Z",
          "iopub.status.idle": "2024-06-03T03:41:51.921585Z",
          "shell.execute_reply": "2024-06-03T03:41:51.920753Z",
          "shell.execute_reply.started": "2024-06-03T03:41:51.883688Z"
        },
        "id": "LWNFOSvLl09H",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dataset First\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBIi_osiCS2"
      },
      "source": [
        "### Dataset Rows & Columns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:51.923776Z",
          "iopub.status.busy": "2024-06-03T03:41:51.923493Z",
          "iopub.status.idle": "2024-06-03T03:41:51.928906Z",
          "shell.execute_reply": "2024-06-03T03:41:51.927988Z",
          "shell.execute_reply.started": "2024-06-03T03:41:51.923753Z"
        },
        "id": "Kllu7SJgmLij",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns\n",
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHwYmJAmNHm"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:51.930477Z",
          "iopub.status.busy": "2024-06-03T03:41:51.930191Z",
          "iopub.status.idle": "2024-06-03T03:41:52.086398Z",
          "shell.execute_reply": "2024-06-03T03:41:52.085197Z",
          "shell.execute_reply.started": "2024-06-03T03:41:51.930448Z"
        },
        "id": "e9hRXRi6meOf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "dataset.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35m5QtbWiB9F"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:52.088629Z",
          "iopub.status.busy": "2024-06-03T03:41:52.087776Z",
          "iopub.status.idle": "2024-06-03T03:41:52.273211Z",
          "shell.execute_reply": "2024-06-03T03:41:52.272371Z",
          "shell.execute_reply.started": "2024-06-03T03:41:52.088590Z"
        },
        "id": "1sLdpKYkmox0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(dataset[dataset.duplicated()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoPl-ycgm1ru"
      },
      "source": [
        "#### Missing Values/Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:52.274465Z",
          "iopub.status.busy": "2024-06-03T03:41:52.274180Z",
          "iopub.status.idle": "2024-06-03T03:41:52.400452Z",
          "shell.execute_reply": "2024-06-03T03:41:52.399586Z",
          "shell.execute_reply.started": "2024-06-03T03:41:52.274441Z"
        },
        "id": "GgHWkxvamxVg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(dataset.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:52.402420Z",
          "iopub.status.busy": "2024-06-03T03:41:52.401975Z",
          "iopub.status.idle": "2024-06-03T03:41:53.050351Z",
          "shell.execute_reply": "2024-06-03T03:41:53.049451Z",
          "shell.execute_reply.started": "2024-06-03T03:41:52.402387Z"
        },
        "id": "bbvXMLwbnbjF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "# Step 1: Calculate the count of missing values in each column and sort in descending order\n",
        "missing_values = dataset.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "\n",
        "# Step 2: Create a horizontal bar plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x=missing_values, y=missing_values.index, orient='h')\n",
        "plt.xlabel('Count of Missing Values')\n",
        "plt.ylabel('Columns')\n",
        "plt.title('Count of Missing Values in Each Column')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0kj-8xxnORC"
      },
      "source": [
        "### What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoNAAC-nUe_"
      },
      "source": [
        "The dataset given is a dataset from E-Commerce industry, and we have to analysis the customers satisfaction score and the insights behind it.\n",
        "\n",
        "Customer Satisfaction Score (CSAT) is a key performance indicator (KPI) used to gauge the level of satisfaction customers have with a company's products, services, or overall experience. In the context of e-commerce, CSAT typically measures how happy customers are with their online shopping experience, including aspects like product quality, website usability, delivery speed, and customer service.\n",
        "\n",
        "CSAT is an essential metric for e-commerce businesses, as it directly reflects the customers' perceptions and experiences, driving both immediate and long-term business success.\n",
        "\n",
        "The above dataset has 85907 rows and 20 columns. There are no duplicate values in the dataset, but there are  mising values in a few columns such as Customer_city,Product_category,item_price,order_id,order_date_time,customer remarks and connected_handling_time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      },
      "source": [
        " ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:53.051808Z",
          "iopub.status.busy": "2024-06-03T03:41:53.051516Z",
          "iopub.status.idle": "2024-06-03T03:41:53.057787Z",
          "shell.execute_reply": "2024-06-03T03:41:53.056901Z",
          "shell.execute_reply.started": "2024-06-03T03:41:53.051784Z"
        },
        "id": "n87BaXA_42-R",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "dataset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:53.062331Z",
          "iopub.status.busy": "2024-06-03T03:41:53.062010Z",
          "iopub.status.idle": "2024-06-03T03:41:53.541987Z",
          "shell.execute_reply": "2024-06-03T03:41:53.541074Z",
          "shell.execute_reply.started": "2024-06-03T03:41:53.062308Z"
        },
        "id": "DnOaZdaE5Q5t",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "dataset.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTbrJXOngz2"
      },
      "source": [
        "### Variables Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGK0kiCdrdEg"
      },
      "source": [
        "**Unique id:** Unique identifier for each record (integer).\n",
        "\n",
        "**Channel name:** Name of the customer service channel (object/string),3 unique channel name.\n",
        "\n",
        "**Category:** Category of the interaction (object/string) ,12 unique category.\n",
        "\n",
        "**Sub-category:** Sub-category of the interaction (object/string),57 unique sub-category.\n",
        "\n",
        "**Customer Remarks:** Feedback provided by the customer (object/string).\n",
        "\n",
        "**Order id:** Identifier for the order associated with the interaction (integer).\n",
        "\n",
        "**Order date time:** Date and time of the order (datetime).\n",
        "\n",
        "**Issue reported at:** Timestamp when the issue was reported (datetime).\n",
        "\n",
        "**Issue responded:** Timestamp when the issue was responded to (datetime).\n",
        "\n",
        "**Survey response date:** Date of the customer survey response (datetime).\n",
        "\n",
        "**Customer city:** City of the customer (object/string),1782 unique Customer city.\n",
        "\n",
        "**Product category:** Category of the product (object/string),9 unique product category.\n",
        "\n",
        "**Item price:** Price of the item (float).\n",
        "\n",
        "**Connected handling time:** Time taken to handle the interaction (float).\n",
        "\n",
        "**Agent name:** Name of the customer service agent (object/string),1371 unique agent name.\n",
        "\n",
        "**Supervisor:** Name of the supervisor (object/string),40 unique Supervisor.\n",
        "\n",
        "**Manager:** Name of the manager (object/string),6 unique manager.\n",
        "\n",
        "**Tenure Bucket:** Bucket categorizing agent tenure (object/string).\n",
        "\n",
        "**Agent Shift:** Shift timing of the agent (object/string).\n",
        "\n",
        "**CSAT Score:** Customer Satisfaction (CSAT) score (integer) (Target-Variable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3PMJOP6ngxN"
      },
      "source": [
        "### Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:53.543477Z",
          "iopub.status.busy": "2024-06-03T03:41:53.543197Z",
          "iopub.status.idle": "2024-06-03T03:41:53.708054Z",
          "shell.execute_reply": "2024-06-03T03:41:53.707159Z",
          "shell.execute_reply.started": "2024-06-03T03:41:53.543454Z"
        },
        "id": "zms12Yq5n-jE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in dataset.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",dataset[i].nunique(),\".\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dauF4eBmngu3"
      },
      "source": [
        "## 3. ***Exploratory Data Analaysis (Data Wrangling)***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:53.709547Z",
          "iopub.status.busy": "2024-06-03T03:41:53.709265Z",
          "iopub.status.idle": "2024-06-03T03:41:53.762499Z",
          "shell.execute_reply": "2024-06-03T03:41:53.761584Z",
          "shell.execute_reply.started": "2024-06-03T03:41:53.709524Z"
        },
        "id": "hf8BBIXE22e4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Create a copy of the current dataset and assigning to df\n",
        "df=dataset.copy()\n",
        "# Checking Shape of True Value\n",
        "print(\"No. of customers interaction and feedbacks with highest customer satisfaction scores  :\",len(df[df['CSAT Score']==5]))\n",
        "# Assigning  customers data to variable df_best_score\n",
        "df_best_score=df[(df['CSAT Score']==5)]\n",
        "df_least_score=df[(df['CSAT Score']==1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwW2pl1O3WwT"
      },
      "source": [
        "### **Q1. Top 5 Product Category with highest Customer Satisfaction Score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:53.764499Z",
          "iopub.status.busy": "2024-06-03T03:41:53.763881Z",
          "iopub.status.idle": "2024-06-03T03:41:53.788985Z",
          "shell.execute_reply": "2024-06-03T03:41:53.788013Z",
          "shell.execute_reply.started": "2024-06-03T03:41:53.764463Z"
        },
        "id": "Ek9jajxU45JV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Groupby Product_category Wise w.r.t Customer satisfaction score data\n",
        "grouped_df = df_best_score.groupby('Product_category').agg(\n",
        "    Count=('CSAT Score', 'size')\n",
        ").sort_values(by='Count',ascending=False)\n",
        "\n",
        "grouped_df[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:53.791300Z",
          "iopub.status.busy": "2024-06-03T03:41:53.790242Z",
          "iopub.status.idle": "2024-06-03T03:41:54.139743Z",
          "shell.execute_reply": "2024-06-03T03:41:54.138795Z",
          "shell.execute_reply.started": "2024-06-03T03:41:53.791266Z"
        },
        "id": "bGBJmOe_4Qs0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plotting the data\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "grouped_df[:5].plot(kind='bar', ax=ax)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xlabel('Product Category')\n",
        "ax.set_ylabel('Count of CSAT Scores')\n",
        "ax.set_title('Top 5 Product Category with highest Customer Satisfaction Score')\n",
        "\n",
        "# Rotating the x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Adding grid for better readability\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXm0OV-S9E2g"
      },
      "source": [
        "### **Q2. Top 5 Category with highest customer satisfaction score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:54.141207Z",
          "iopub.status.busy": "2024-06-03T03:41:54.140918Z",
          "iopub.status.idle": "2024-06-03T03:41:54.161847Z",
          "shell.execute_reply": "2024-06-03T03:41:54.160981Z",
          "shell.execute_reply.started": "2024-06-03T03:41:54.141183Z"
        },
        "id": "TQ-wDXYs9Qhj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Groupby Customer_City Wise w.r.t Customer satisfaction score data\n",
        "grouped_df = df_best_score.groupby('category').agg(\n",
        "    Count=('CSAT Score', 'size')\n",
        ").sort_values(by='Count',ascending=False)\n",
        "\n",
        "grouped_df[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:54.163202Z",
          "iopub.status.busy": "2024-06-03T03:41:54.162869Z",
          "iopub.status.idle": "2024-06-03T03:41:54.420018Z",
          "shell.execute_reply": "2024-06-03T03:41:54.419014Z",
          "shell.execute_reply.started": "2024-06-03T03:41:54.163169Z"
        },
        "id": "_ihGFAML9goW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Plotting the data\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "grouped_df[:5].plot(kind='bar', ax=ax)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xlabel('Category')\n",
        "ax.set_ylabel('Count of CSAT Scores')\n",
        "ax.set_title('Top 5 Categories with highest Customer Satisfaction Score')\n",
        "\n",
        "# Rotating the x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Adding grid for better readability\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5pG0ENk5O63"
      },
      "source": [
        "### **Q3. Top 5 Sub Category with highest Customer Satisfaction Score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:54.422082Z",
          "iopub.status.busy": "2024-06-03T03:41:54.421737Z",
          "iopub.status.idle": "2024-06-03T03:41:54.444434Z",
          "shell.execute_reply": "2024-06-03T03:41:54.443533Z",
          "shell.execute_reply.started": "2024-06-03T03:41:54.422057Z"
        },
        "id": "NLpBbO8q8fBO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Groupby Sub-category Wise w.r.t Customer satisfaction score data\n",
        "grouped_df = df_best_score.groupby('Sub-category').agg(\n",
        "    Count=('CSAT Score', 'size')\n",
        ").sort_values(by='Count',ascending=False)\n",
        "\n",
        "grouped_df[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:54.445804Z",
          "iopub.status.busy": "2024-06-03T03:41:54.445487Z",
          "iopub.status.idle": "2024-06-03T03:41:54.785083Z",
          "shell.execute_reply": "2024-06-03T03:41:54.784184Z",
          "shell.execute_reply.started": "2024-06-03T03:41:54.445779Z"
        },
        "id": "-CmN_LSP547X",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plotting the data\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "grouped_df[:5].plot(kind='bar', ax=ax)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xlabel('Sub Category')\n",
        "ax.set_ylabel('Count of CSAT Scores')\n",
        "ax.set_title('Top 5 Sub Category with highest Customer Satisfaction Score')\n",
        "\n",
        "# Rotating the x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Adding grid for better readability\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0QVFX0B8C8x"
      },
      "source": [
        "### **Q4. Top 5 cities with highest customer satisfaction score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:54.787121Z",
          "iopub.status.busy": "2024-06-03T03:41:54.786374Z",
          "iopub.status.idle": "2024-06-03T03:41:54.810983Z",
          "shell.execute_reply": "2024-06-03T03:41:54.810014Z",
          "shell.execute_reply.started": "2024-06-03T03:41:54.787082Z"
        },
        "id": "0JBLdnPH6re2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Groupby Customer_City Wise w.r.t Customer satisfaction score data\n",
        "grouped_df = df_best_score.groupby('Customer_City').agg(\n",
        "    Count=('CSAT Score', 'size')\n",
        ").sort_values(by='Count',ascending=False)\n",
        "\n",
        "grouped_df[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:54.812341Z",
          "iopub.status.busy": "2024-06-03T03:41:54.812086Z",
          "iopub.status.idle": "2024-06-03T03:41:55.141582Z",
          "shell.execute_reply": "2024-06-03T03:41:55.140670Z",
          "shell.execute_reply.started": "2024-06-03T03:41:54.812321Z"
        },
        "id": "j1_fDvIT83uB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plotting the data\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "grouped_df[:5].plot(kind='bar', ax=ax)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xlabel('Cities')\n",
        "ax.set_ylabel('Count of CSAT Scores')\n",
        "ax.set_title('Top 5 Cities with highest Customer Satisfaction Score')\n",
        "\n",
        "# Rotating the x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Adding grid for better readability\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNouVC-U62KI"
      },
      "source": [
        "### **Q5. Best performing Channels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:55.143089Z",
          "iopub.status.busy": "2024-06-03T03:41:55.142791Z",
          "iopub.status.idle": "2024-06-03T03:41:55.162171Z",
          "shell.execute_reply": "2024-06-03T03:41:55.161279Z",
          "shell.execute_reply.started": "2024-06-03T03:41:55.143054Z"
        },
        "id": "Zv9cJLcI8JGt",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Groupby Channel name Wise w.r.t Customer satisfaction score data\n",
        "grouped_df = df_best_score.groupby('channel_name').agg(\n",
        "    Count=('CSAT Score', 'size')\n",
        ").sort_values(by='Count',ascending=False)\n",
        "\n",
        "grouped_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:55.163757Z",
          "iopub.status.busy": "2024-06-03T03:41:55.163379Z",
          "iopub.status.idle": "2024-06-03T03:41:55.452574Z",
          "shell.execute_reply": "2024-06-03T03:41:55.451691Z",
          "shell.execute_reply.started": "2024-06-03T03:41:55.163725Z"
        },
        "id": "ttetFGHr6qlU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plotting the data\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "grouped_df[:5].plot(kind='bar', ax=ax)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xlabel('Channels')\n",
        "ax.set_ylabel('Count of CSAT Scores')\n",
        "ax.set_title('Channel with highest Customer Satisfaction Score')\n",
        "\n",
        "# Rotating the x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Adding grid for better readability\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NNA-0cy-dcQ"
      },
      "source": [
        "### **Q6. Top 3 best performing Managers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:55.454673Z",
          "iopub.status.busy": "2024-06-03T03:41:55.453985Z",
          "iopub.status.idle": "2024-06-03T03:41:55.477243Z",
          "shell.execute_reply": "2024-06-03T03:41:55.476387Z",
          "shell.execute_reply.started": "2024-06-03T03:41:55.454615Z"
        },
        "id": "YNCHUNGA-fKY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Groupby Manager Wise w.r.t Customer satisfaction score data\n",
        "grouped_df = df_best_score.groupby('Manager').agg(\n",
        "    Count=('CSAT Score', 'size')\n",
        ").sort_values(by='Count',ascending=False)\n",
        "\n",
        "grouped_df[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:55.478983Z",
          "iopub.status.busy": "2024-06-03T03:41:55.478617Z",
          "iopub.status.idle": "2024-06-03T03:41:55.790690Z",
          "shell.execute_reply": "2024-06-03T03:41:55.789810Z",
          "shell.execute_reply.started": "2024-06-03T03:41:55.478956Z"
        },
        "id": "ceinX08y_FL4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plotting the data\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "grouped_df[:3].plot(kind='bar', ax=ax)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xlabel('Manager Name')\n",
        "ax.set_ylabel('Count of CSAT Scores')\n",
        "ax.set_title('Managers with highest Customer Satisfaction Score')\n",
        "\n",
        "# Rotating the x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Adding grid for better readability\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3CETLqIAO6f"
      },
      "source": [
        "### **Q7. Top 3 best performing Agents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:55.792615Z",
          "iopub.status.busy": "2024-06-03T03:41:55.791975Z",
          "iopub.status.idle": "2024-06-03T03:41:55.816905Z",
          "shell.execute_reply": "2024-06-03T03:41:55.816104Z",
          "shell.execute_reply.started": "2024-06-03T03:41:55.792581Z"
        },
        "id": "w7O1lQ-2_eK_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Groupby Agent_name Wise w.r.t Customer satisfaction score data\n",
        "grouped_df = df_best_score.groupby('Agent_name').agg(\n",
        "    Count=('CSAT Score', 'size')\n",
        ").sort_values(by='Count',ascending=False)\n",
        "\n",
        "grouped_df[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:55.818235Z",
          "iopub.status.busy": "2024-06-03T03:41:55.817945Z",
          "iopub.status.idle": "2024-06-03T03:41:56.055872Z",
          "shell.execute_reply": "2024-06-03T03:41:56.054979Z",
          "shell.execute_reply.started": "2024-06-03T03:41:55.818211Z"
        },
        "id": "lWt0erua_plf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plotting the data\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "grouped_df[:3].plot(kind='bar', ax=ax)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xlabel('Agent Name')\n",
        "ax.set_ylabel('Count of CSAT Scores')\n",
        "ax.set_title('Agents with highest Customer Satisfaction Score')\n",
        "\n",
        "# Rotating the x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Adding grid for better readability\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YbDiZh7A-_O"
      },
      "source": [
        "### **Q8. Top 3 best performing Supervisors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:56.057233Z",
          "iopub.status.busy": "2024-06-03T03:41:56.056940Z",
          "iopub.status.idle": "2024-06-03T03:41:56.077365Z",
          "shell.execute_reply": "2024-06-03T03:41:56.076473Z",
          "shell.execute_reply.started": "2024-06-03T03:41:56.057208Z"
        },
        "id": "8SwK6JJpAo7k",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Groupby Supervisor Wise w.r.t Customer satisfaction score data\n",
        "grouped_df = df_best_score.groupby('Supervisor').agg(\n",
        "    Count=('CSAT Score', 'size')\n",
        ").sort_values(by='Count',ascending=False)\n",
        "\n",
        "grouped_df[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:56.087586Z",
          "iopub.status.busy": "2024-06-03T03:41:56.087259Z",
          "iopub.status.idle": "2024-06-03T03:41:56.334275Z",
          "shell.execute_reply": "2024-06-03T03:41:56.333298Z",
          "shell.execute_reply.started": "2024-06-03T03:41:56.087563Z"
        },
        "id": "w-c5WHwRAzhE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plotting the data\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "grouped_df[:3].plot(kind='bar', ax=ax)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xlabel('Supervisor Name')\n",
        "ax.set_ylabel('Count of CSAT Scores')\n",
        "ax.set_title('Supervisors with highest Customer Satisfaction Score')\n",
        "\n",
        "# Rotating the x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Adding grid for better readability\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzCh2lklBEsf"
      },
      "source": [
        "### **Q9. Which tenure group of employees is performing the best?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:56.336144Z",
          "iopub.status.busy": "2024-06-03T03:41:56.335641Z",
          "iopub.status.idle": "2024-06-03T03:41:56.357423Z",
          "shell.execute_reply": "2024-06-03T03:41:56.356536Z",
          "shell.execute_reply.started": "2024-06-03T03:41:56.336107Z"
        },
        "id": "NnTFPAV8B7Yq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Groupby Supervisor Wise w.r.t Customer satisfaction score data\n",
        "grouped_df = df_best_score.groupby('Tenure Bucket').agg(\n",
        "    Count=('CSAT Score', 'size')\n",
        ").sort_values(by='Count',ascending=False)\n",
        "\n",
        "grouped_df[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:56.359685Z",
          "iopub.status.busy": "2024-06-03T03:41:56.358996Z",
          "iopub.status.idle": "2024-06-03T03:41:56.641478Z",
          "shell.execute_reply": "2024-06-03T03:41:56.640603Z",
          "shell.execute_reply.started": "2024-06-03T03:41:56.359633Z"
        },
        "id": "D7je_-GHCDny",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plotting the data\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "grouped_df[:3].plot(kind='bar', ax=ax)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xlabel('Tenure bucket')\n",
        "ax.set_ylabel('Count of CSAT Scores')\n",
        "ax.set_title('Tenure group with highest Customer Satisfaction Score')\n",
        "\n",
        "# Rotating the x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Adding grid for better readability\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmPcFk5iFH6C"
      },
      "source": [
        "### **Q10. Which shift timings of agents is performing the best?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:56.643185Z",
          "iopub.status.busy": "2024-06-03T03:41:56.642832Z",
          "iopub.status.idle": "2024-06-03T03:41:56.663925Z",
          "shell.execute_reply": "2024-06-03T03:41:56.662979Z",
          "shell.execute_reply.started": "2024-06-03T03:41:56.643145Z"
        },
        "id": "8ezRFAPLE9w4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Groupby Supervisor Wise w.r.t Customer satisfaction score data\n",
        "grouped_df = df_best_score.groupby('Agent Shift').agg(\n",
        "    Count=('CSAT Score', 'size')\n",
        ").sort_values(by='Count',ascending=False)\n",
        "\n",
        "grouped_df[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:56.665604Z",
          "iopub.status.busy": "2024-06-03T03:41:56.665236Z",
          "iopub.status.idle": "2024-06-03T03:41:56.960721Z",
          "shell.execute_reply": "2024-06-03T03:41:56.959776Z",
          "shell.execute_reply.started": "2024-06-03T03:41:56.665572Z"
        },
        "id": "VIROyUW4E_xx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plotting the data\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "grouped_df[:3].plot(kind='bar', ax=ax)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xlabel('Agents Shift Timings')\n",
        "ax.set_ylabel('Count of CSAT Scores')\n",
        "ax.set_title('Shift Timings with highest Customer Satisfaction Score')\n",
        "\n",
        "# Rotating the x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Adding grid for better readability\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYy5gcchKnaH"
      },
      "source": [
        "### **Q11. How response time impacts the customer satisfaction score?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:56.962218Z",
          "iopub.status.busy": "2024-06-03T03:41:56.961945Z",
          "iopub.status.idle": "2024-06-03T03:41:57.860188Z",
          "shell.execute_reply": "2024-06-03T03:41:57.859203Z",
          "shell.execute_reply.started": "2024-06-03T03:41:56.962195Z"
        },
        "id": "hP-WWOvBG1k7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Ensure the 'Issue reported at' and 'Issue responded' columns are in datetime format\n",
        "df['Issue_reported at'] = pd.to_datetime(df['Issue_reported at'], dayfirst=True)\n",
        "df['issue_responded'] = pd.to_datetime(df['issue_responded'], dayfirst=True)\n",
        "\n",
        "# Calculate the response time\n",
        "df['Response_Time'] = df['issue_responded'] - df['Issue_reported at']\n",
        "\n",
        "# Convert 'Response_Time' to a numerical format in seconds for aggregation\n",
        "df['Response_Time_seconds'] = df['Response_Time'].dt.total_seconds()\n",
        "\n",
        "# Groupby CSAT Score and calculate the mean response time\n",
        "grouped_df = df.groupby('CSAT Score').agg(\n",
        "    Mean_Response_Time=('Response_Time_seconds', 'mean')\n",
        ").sort_values(by='Mean_Response_Time', ascending=False)\n",
        "\n",
        "# Convert the mean response time back to timedelta for readability\n",
        "grouped_df['Mean_Response_Time'] = pd.to_timedelta(grouped_df['Mean_Response_Time'], unit='s')\n",
        "\n",
        "# Display the grouped DataFrame\n",
        "print(grouped_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:57.861805Z",
          "iopub.status.busy": "2024-06-03T03:41:57.861476Z",
          "iopub.status.idle": "2024-06-03T03:41:58.193451Z",
          "shell.execute_reply": "2024-06-03T03:41:58.192594Z",
          "shell.execute_reply.started": "2024-06-03T03:41:57.861779Z"
        },
        "id": "TfKn5cIMKEcB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plotting the data\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "grouped_df.plot(kind='bar', ax=ax)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xlabel('CSAT Scores')\n",
        "ax.set_ylabel('Mean Response Time')\n",
        "ax.set_title('Mean Response Time in each Customer Satisfaction Score')\n",
        "\n",
        "# Rotating the x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Adding grid for better readability\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7gi-LRXLeZl"
      },
      "source": [
        "### **Q12. How customer handling time duration impacts the customer satisfaction score?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:58.195528Z",
          "iopub.status.busy": "2024-06-03T03:41:58.194743Z",
          "iopub.status.idle": "2024-06-03T03:41:58.212539Z",
          "shell.execute_reply": "2024-06-03T03:41:58.211673Z",
          "shell.execute_reply.started": "2024-06-03T03:41:58.195495Z"
        },
        "id": "alkDICeyLs2M",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Groupby Customer satisfaction score data w.r.t customer handling time\n",
        "grouped_df = df.groupby('CSAT Score').agg(\n",
        "    Mean_Response_Time=('connected_handling_time', 'mean')\n",
        ").sort_values(by='Mean_Response_Time', ascending=False)\n",
        "\n",
        "grouped_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:58.213810Z",
          "iopub.status.busy": "2024-06-03T03:41:58.213519Z",
          "iopub.status.idle": "2024-06-03T03:41:58.516908Z",
          "shell.execute_reply": "2024-06-03T03:41:58.515955Z",
          "shell.execute_reply.started": "2024-06-03T03:41:58.213786Z"
        },
        "id": "52fva9q2Mt7d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plotting the data\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "grouped_df.plot(kind='bar', ax=ax)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xlabel('CSAT Scores')\n",
        "ax.set_ylabel('Mean Customer Handling Time')\n",
        "ax.set_title('Mean Customer Handling Time in each Customer Satisfaction Score')\n",
        "\n",
        "# Rotating the x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Adding grid for better readability\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSa1f5Uengrz"
      },
      "source": [
        "### What all manipulations have you done and insights you found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7Sf9RblRrPD"
      },
      "source": [
        "Based on the provided data, we aimed to gain a clear understanding of customer satisfaction scores through graphical representations. However, it is crucial to delve deeper into the behavior of customers with varying satisfaction scores to uncover insights and hypothetical statements that might explain the reasons behind these scores. Thus, I focused on the data of customers with high satisfaction scores to identify patterns and potential reasons for their satisfaction.\n",
        "\n",
        "Potential reasons for lower customer satisfaction scores are noted below based on the findings from the analysis:\n",
        "\n",
        "**Insights from Analysis:**\n",
        "\n",
        "**Response Time:** Identified that longer response times were correlated with lower customer satisfaction scores. This suggests a need for quicker response mechanisms.\n",
        "\n",
        "**Product Category:** Found that certain product categories had consistently lower satisfaction scores, indicating potential issues with these products or their support processes.\n",
        "\n",
        "**Channel Name:** Discovered that certain customer service channels were more effective at resolving issues satisfactorily, leading to higher CSAT scores.\n",
        "\n",
        "**Agent Tenure:** Noted that agents with longer tenures tended to receive higher satisfaction scores, suggesting that experience plays a crucial role in customer service effectiveness.\n",
        "\n",
        "**Shift Timings:** Found variations in satisfaction scores based on agent shifts, with some shifts having lower scores, possibly due to higher workloads or fewer resources during those times.\n",
        "\n",
        "**Customer Feedback:** Analyzed customer remarks to identify common themes and keywords associated with low satisfaction scores, providing qualitative insights into customer pain points.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8Ens_Soomf"
      },
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--"
      },
      "source": [
        "#### Chart - 1 - Pie Chart on Dependant Variable i.e., CSAT Score (Univariate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:58.518231Z",
          "iopub.status.busy": "2024-06-03T03:41:58.517978Z",
          "iopub.status.idle": "2024-06-03T03:41:58.752143Z",
          "shell.execute_reply": "2024-06-03T03:41:58.750814Z",
          "shell.execute_reply.started": "2024-06-03T03:41:58.518209Z"
        },
        "id": "7v_ESjsspbW7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Chart - 1 visualization code\n",
        "# Dependant Column Value Counts\n",
        "# Display the value counts of the 'CSAT Score' column\n",
        "print(df['CSAT Score'].value_counts())\n",
        "print(\" \")\n",
        "\n",
        "# Visualize the 'CSAT Score' value counts as a pie chart\n",
        "df['CSAT Score'].value_counts().plot(\n",
        "    kind='pie',\n",
        "    figsize=(15, 6),\n",
        "    autopct=\"%1.1f%%\",\n",
        "    startangle=90,\n",
        "    shadow=True,\n",
        "    labels=df['CSAT Score'].value_counts().index,\n",
        "    colors=plt.cm.Paired(range(len(df['CSAT Score'].value_counts()))),\n",
        "    explode=[0.1] * len(df['CSAT Score'].value_counts())  # Slightly explode all slices for better visibility\n",
        ")\n",
        "\n",
        "# Set the title and display the plot\n",
        "plt.title('Customer Satisfaction Score Distribution')\n",
        "plt.ylabel('')  # Hide the y-label as it's redundant in a pie chart\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5QZ13OEpz2H"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        "A pie chart expresses a part-to-whole relationship in your data. It's easy to explain the percentage comparison through area covered in a circle with different colors. Where differenet percentage comparison comes into action pie chart is used frequently. So, I used Pie chart and which helped me to get the percentage comparision of the dependant variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_j1G7yiqdRP"
      },
      "source": [
        "Based on the chart, I observed that 59,617 customers rated the service with a CSAT Score of 5, which accounts for 69.4% of the total feedback in the dataset. Conversely, 1,283 customers were dissatisfied and gave a CSAT Score of 2, representing 1.5% of the total responses.\n",
        "\n",
        "Additionally, 13.1% of customers gave a poor CSAT score of 1, another 13.1% rated it as 4, and 3% of customers provided a score of 3. This means nearly 15% of customers experienced poor service. Therefore, it is crucial to examine the factors contributing to this dissatisfaction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxquiKWpK14X"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ1DGDxyKc6a"
      },
      "source": [
        "Yes, the gained insights will help create a positive business impact. Here's how:\n",
        "\n",
        "**Focus on Strengths:** Knowing that 69.4% of customers rated the service with a CSAT score of 5 indicates a strong positive reception. By analyzing what is working well for these satisfied customers, the business can replicate these strategies across other areas to further enhance customer satisfaction.\n",
        "\n",
        "**Targeted Improvements:** Identifying that 15% of customers are experiencing poor service (CSAT scores of 1, 2, and 3) allows the business to focus on specific areas of improvement. Understanding the reasons behind these low scores can help address the root causes, such as response time, service quality, or specific product issues.\n",
        "\n",
        "**Resource Allocation:** Insights into customer satisfaction distribution can guide the allocation of resources. For instance, more training and support can be provided to agents or departments that receive lower scores to elevate their performance.\n",
        "\n",
        "**Strategic Planning:** The data can be used to set targeted goals for improvement in customer satisfaction metrics, driving a continuous improvement culture within the organization.\n",
        "Are there any insights that lead to negative growth? Justify with specific reasons.\n",
        "\n",
        "While the insights primarily aim to create a positive impact, if not properly managed, they could potentially lead to negative growth:\n",
        "\n",
        "**Neglecting High Performers:** If the focus shifts too heavily on addressing negative feedback without recognizing and maintaining what leads to high satisfaction (69.4% with a score of 5), there is a risk of neglecting the positive aspects. This could inadvertently lead to a decline in the areas that are currently performing well.\n",
        "\n",
        "**Inadequate Response to Poor Scores:** If the business fails to adequately address the issues leading to the 15% of poor scores, customer dissatisfaction could worsen. Dissatisfied customers are more likely to churn, leave negative reviews, and dissuade potential customers, negatively impacting growth.\n",
        "Overemphasis on Quick Fixes: Prioritizing quick fixes over sustainable, long-term solutions can lead to temporary improvements in CSAT scores without addressing underlying issues. This might result in a superficial improvement in customer satisfaction but could cause long-term dissatisfaction if deeper problems are ignored.\n",
        "\n",
        "**Justification with Specific Reasons**\n",
        "\n",
        "**Positive Business Impact:** The insights provide a clear indication of customer satisfaction levels and areas needing improvement. For instance, since a significant majority (69.4%) are highly satisfied, the business can study and reinforce the strategies that contribute to high satisfaction. Additionally, addressing the 15% of poor scores by understanding and resolving their causes will likely result in improved overall customer satisfaction and loyalty.\n",
        "\n",
        "**Potential for Negative Growth:** Ignoring the insights related to low satisfaction scores or failing to act on them effectively could lead to increased dissatisfaction. For example, if the business does not address the issues faced by the 1.5% of customers who gave a score of 2, this dissatisfaction can spread, potentially leading to higher churn rates and negative word-of-mouth. Similarly, failing to balance efforts between maintaining high satisfaction levels and improving lower ones can also be detrimental.\n",
        "\n",
        "In conclusion, the insights have the potential to drive positive business impact by highlighting areas of strength and weakness. However, careful and balanced management of these insights is crucial to avoid any negative consequences and ensure sustained growth and customer satisfaction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJivPyE8q_2k"
      },
      "source": [
        "#### Chart - 2 - Agent Vs. Average Response Time Percentage (Bivariate with Categorical - Numerical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:58.755271Z",
          "iopub.status.busy": "2024-06-03T03:41:58.754075Z",
          "iopub.status.idle": "2024-06-03T03:41:59.243443Z",
          "shell.execute_reply": "2024-06-03T03:41:59.242469Z",
          "shell.execute_reply.started": "2024-06-03T03:41:58.755222Z"
        },
        "id": "NTkxmIkWq_20",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Chart - 2 visualization code\n",
        "# Showing Average True Churn Percentage state wise\n",
        "# Showing top 10 churned state\n",
        "print((df.groupby(['Agent_name'])['Response_Time_seconds'].mean()*100).sort_values(ascending = False).reset_index(name=\"Average Response Time %\").head(10))\n",
        "print(\" \")\n",
        "\n",
        "# State vs. average true churn percantage visualization code\n",
        "# Vizualizing top 10 churned state\n",
        "plt.rcParams['figure.figsize'] = (12, 7)\n",
        "color = plt.cm.copper(np.linspace(0, 0.5, 20))\n",
        "((df.groupby(['Agent_name'])['Response_Time_seconds'].mean())*100).sort_values(ascending = False).head(10).plot.bar(color = ['violet','indigo','b','g','y','orange','r'])\n",
        "plt.title(\" Agent average Response_Time_seconds percentage\", fontsize = 20)\n",
        "plt.xlabel('Agent', fontsize = 15)\n",
        "plt.ylabel('percentage', fontsize = 15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azX1PEddq_20"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTXVnJ-fq_20"
      },
      "source": [
        "Bar charts show the frequency counts of values for the different levels of a categorical or nominal variable. Sometimes, bar charts show other statistics, such as percentages.\n",
        "\n",
        "To show the average percentage of response time with respect to agents, I have used Bar Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyKleWeyq_20"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwesNe8zq_21"
      },
      "source": [
        "There are 10 agents with varying average response times.\n",
        "\n",
        "The average response times by agent range from 2.09 to 4.09 hours. Elizabeth Rose and Donald Jordan have the shortest average response times, providing the best service to their clients through prompt action.\n",
        "\n",
        "On the other hand, Christine Castro has the longest average response time for addressing client queries. Therefore, evaluating her performance and providing additional training is crucial to enhance the CSAT Score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-UX51ofq_21"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW7-bqD0q_21"
      },
      "source": [
        "Yes, the insights gained can help create a positive business impact. By identifying which agents have the shortest and longest response times, businesses can take specific actions to improve overall customer satisfaction:\n",
        "\n",
        "**Performance Recognition:** Recognizing and rewarding agents like Elizabeth Rose and Donald Jordan for their exemplary service can boost morale and set a benchmark for other agents.\n",
        "\n",
        "**Targeted Training:** Providing additional training and support to agents like Christine Castro can help reduce response times, leading to better customer experiences and potentially higher CSAT scores.\n",
        "\n",
        "**Resource Allocation:** Understanding the distribution of response times can help in reallocating resources and support where needed most, ensuring a more balanced and efficient customer service operation.\n",
        "\n",
        "**Process Improvements:** Identifying bottlenecks and inefficiencies in the service process can lead to improvements that benefit all agents and customers, enhancing overall service quality.\n",
        "\n",
        "**Are there any insights that lead to negative growth?**\n",
        "\n",
        "There are no direct insights that would lead to negative growth; however, if not acted upon appropriately, some insights could potentially have a negative impact:\n",
        "\n",
        "**Failure to Address Poor Performance:** If agents with high response times are not given the necessary training and support, customer dissatisfaction may continue or worsen, leading to negative reviews and loss of customers.\n",
        "\n",
        "**Ignoring Top Performers:** Not recognizing and rewarding top-performing agents could lead to decreased motivation and performance over time, potentially affecting overall service quality.\n",
        "\n",
        "**Overemphasis on Speed:** Focusing solely on reducing response times without maintaining quality of service might lead to rushed interactions and unresolved issues, which could harm customer satisfaction in the long run.\n",
        "\n",
        "**Justification with Specific Reasons**\n",
        "\n",
        "**Positive Business Impact:** By addressing the variations in response times, the business can ensure a more consistent and satisfactory customer experience. For instance, agents like Elizabeth Rose and Donald Jordan, who provide quick responses, set a standard for others. This can be leveraged through training programs to improve the performance of other agents.\n",
        "\n",
        "**Potential for Negative Growth:** If insights are ignored, such as the need for retraining agents with higher response times like Christine Castro, customer dissatisfaction may persist. Dissatisfied customers are more likely to churn and spread negative word-of-mouth, which can harm the businesss reputation and growth prospects.\n",
        "\n",
        "In conclusion, the insights gained will likely foster a positive business impact if acted upon effectively, leading to improved customer satisfaction and service quality. However, neglecting these insights or mismanaging the response to them could result in negative growth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of3PJYNbrGff"
      },
      "source": [
        "#### Chart - 3 - Box Plot on Connected handling time with CSAT Score (Bivariate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:59.244813Z",
          "iopub.status.busy": "2024-06-03T03:41:59.244498Z",
          "iopub.status.idle": "2024-06-03T03:41:59.577783Z",
          "shell.execute_reply": "2024-06-03T03:41:59.576789Z",
          "shell.execute_reply.started": "2024-06-03T03:41:59.244776Z"
        },
        "id": "o8OOv8dKphvC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Box Plot for connected_handling_time attribute w.r.t to CSAT Score\n",
        "df.boxplot(column='connected_handling_time',by='CSAT Score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8bcvZxarGfg"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-GBsMEqrGfg"
      },
      "source": [
        "\n",
        "\n",
        "Box plots are used to show distributions of numeric data values, especially when you want to compare them between multiple groups. They are built to provide high-level information at a glance, offering general information about a group of data's symmetry, skew, variance, and outliers. So, I used box plot to get the maximum and minimum value with well sagreggated outliers with well defined mean and median as shown in the box plot graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ6txCBBrGfh"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X7Ff9HFrGfh"
      },
      "source": [
        "From the above boxplot, we can observe that there are a few outliers in the CSAT Scores of 4 and 5. Specifically, outliers appear when the connected handling time exceeds 750 for CSAT Score 4, and when it exceeds 1000 for CSAT Score 5. Analyzing these outliers is crucial for understanding the underlying factors contributing to these anomalies.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbkhcZqdrGfh"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZjMyjAHrGfh"
      },
      "source": [
        "Yes, the insights gained can help create a positive business impact. Here's how:\n",
        "\n",
        "**Targeted Improvements:** By identifying outliers in CSAT Scores when the connected handling time is high, the business can focus on improving processes that lead to long handling times. Reducing these handling times can enhance customer satisfaction.\n",
        "**Quality Control:** Understanding why CSAT Scores drop when handling times increase will allow the business to implement quality control measures. This can involve additional training for agents, better resource allocation, or process optimizations.\n",
        "**Customer Experience Enhancement:** By addressing the factors leading to long handling times and subsequent lower satisfaction scores, the business can improve the overall customer experience, which can lead to increased loyalty and positive word-of-mouth.\n",
        "\n",
        "Are there any insights that lead to negative growth?\n",
        "\n",
        "While the primary goal of the insights is to foster positive business impact, there could be potential risks if not managed properly:\n",
        "\n",
        "**Overemphasis on Speed:** If the business focuses too much on reducing handling times without ensuring the quality of interactions, it might lead to rushed and ineffective customer service. This can result in unresolved issues and lower overall satisfaction.\n",
        "\n",
        "**Neglecting Non-Outlier Data:** Focusing exclusively on outliers might lead to neglecting the broader dataset. Improvements should be holistic, ensuring that all areas of customer service are enhanced, not just those with extreme values.\n",
        "\n",
        "\n",
        "**Justification with Specific Reasons**\n",
        "\n",
        "**Positive Business Impact:** Addressing the outliers in CSAT Scores related to high handling times can directly improve customer satisfaction by ensuring quicker and more efficient service. For instance, by training agents to handle calls more effectively or by implementing better call routing systems, the business can reduce handling times and thus improve scores.\n",
        "\n",
        "**Potential for Negative Growth:** If the business focuses solely on reducing handling times without maintaining the quality of interactions, it may lead to superficial improvements in satisfaction scores. For example, customers might experience quicker service but still be dissatisfied if their issues are not fully resolved. Additionally, neglecting other areas in need of improvement can result in an overall decline in service quality.\n",
        "\n",
        "In conclusion, while the insights can lead to positive business impacts by targeting and resolving specific issues, a balanced and comprehensive approach is essential to avoid any potential negative growth and ensure sustainable improvements in customer satisfaction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riLp7y9brHca"
      },
      "source": [
        "#### Chart - 4 - CSAT Score vs Item price (Bivariate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:59.579735Z",
          "iopub.status.busy": "2024-06-03T03:41:59.579302Z",
          "iopub.status.idle": "2024-06-03T03:41:59.873777Z",
          "shell.execute_reply": "2024-06-03T03:41:59.872777Z",
          "shell.execute_reply.started": "2024-06-03T03:41:59.579699Z"
        },
        "id": "QQ-DWHW5rHca",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Chart - 4 visualization code\n",
        "# CSAT Score wise average Item_price Percentage\n",
        "# Calculate the average item price percentage by CSAT Score\n",
        "csat_avg_item_price_percentage = dataset.groupby('CSAT Score')['Item_price'].mean() * 100\n",
        "print(csat_avg_item_price_percentage)\n",
        "print(\" \")\n",
        "\n",
        "# Visualizing the CSAT Score wise average item price percentage\n",
        "plt.bar(csat_avg_item_price_percentage.index, csat_avg_item_price_percentage, color=['r', 'b', 'g', 'c', 'm'])\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (10, 6)  # Adjust the figure size\n",
        "plt.xlabel('CSAT Score', fontsize=15)\n",
        "plt.ylabel('Item Price Percentage', fontsize=15)\n",
        "plt.title('CSAT Score Wise Average Item Price Percentage', fontsize=18)\n",
        "plt.xticks(csat_avg_item_price_percentage.index, fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw0GT_uHrHcb"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7c_a-IXrHcb"
      },
      "source": [
        "Bar charts show the frequency counts of values for the different levels of a categorical or nominal variable. Sometimes, bar charts show other statistics, such as percentages.\n",
        "\n",
        "To show the average percentage of true churn with respect to Area Code, I have used Bar Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTEiGUKorHcc"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3rmtW3vrHcc"
      },
      "source": [
        "From the bar graph, it is evident that the mean item price is highest when the CSAT score is 1 and lowest when the CSAT score is 5. This indicates an inverse correlation between item price and CSAT score, suggesting that higher item prices are generally associated with lower customer satisfaction scores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qw8mtL3rHcd"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7dguLynrHcd"
      },
      "source": [
        "Yes, the insights can help create a positive business impact in the following ways:\n",
        "\n",
        "**Pricing Strategy:** Understanding that higher item prices are associated with lower CSAT scores can guide pricing strategies. By adjusting prices or offering better value at higher price points, businesses can improve customer satisfaction.\n",
        "\n",
        "**Customer Segmentation:** These insights can help in segmenting customers based on their spending behavior and satisfaction levels. Targeted promotions and personalized offers can be designed to enhance satisfaction among different customer segments.\n",
        "\n",
        " **Are there any insights that lead to negative growth?**\n",
        "\n",
        "There are potential risks if the insights are not managed properly:\n",
        "\n",
        "**Price Reduction Risks:** Simply lowering prices to improve CSAT scores might not be sustainable and could negatively impact profitability. Businesses need to balance price adjustments with maintaining profit margins.\n",
        "\n",
        "**Overemphasis on Price:** Focusing solely on price without addressing other factors that contribute to customer satisfaction (such as product quality, customer service, and overall experience) may not yield the desired improvement in CSAT scores.\n",
        "\n",
        "**Justification with Specific Reasons**\n",
        "\n",
        "**Positive Business Impact:** By aligning pricing strategies with customer expectations, businesses can enhance customer satisfaction. For instance, offering more features or better service for higher-priced items can justify the cost and improve CSAT scores. Additionally, personalized marketing strategies based on customer segments can lead to increased loyalty and repeat purchases.\n",
        "\n",
        "**Potential for Negative Growth:** If businesses reduce prices without maintaining value, it can lead to a perception of reduced quality. For example, if a high-end product's price is reduced significantly without adding corresponding value, customers might perceive it as less premium, leading to lower sales. Additionally, overemphasizing price reductions can erode profit margins, affecting the overall financial health of the business.\n",
        "\n",
        "In conclusion, while the insights provide valuable guidance for improving customer satisfaction and driving positive business impact, it is crucial to implement them thoughtfully. Balancing price adjustments with value enhancement and considering all factors affecting customer satisfaction will help avoid potential negative consequences and ensure sustainable growth.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3aNiIh9fKqZ"
      },
      "source": [
        "#### Chart - 5- Column wise Histogram & Box Plot Univariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:41:59.875125Z",
          "iopub.status.busy": "2024-06-03T03:41:59.874871Z",
          "iopub.status.idle": "2024-06-03T03:42:02.378961Z",
          "shell.execute_reply": "2024-06-03T03:42:02.377921Z",
          "shell.execute_reply.started": "2024-06-03T03:41:59.875104Z"
        },
        "id": "WPVINT_UfKqa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Chart - 5 visualization code\n",
        "# Visualizing code of hist plot for each columns to know the data distibution\n",
        "for col in dataset.describe().columns:\n",
        "  fig=plt.figure(figsize=(9,6))\n",
        "  ax=fig.gca()\n",
        "  feature= (dataset[col])\n",
        "  sns.distplot(dataset[col])\n",
        "  ax.axvline(feature.mean(),color='magenta', linestyle='dashed', linewidth=2)\n",
        "  ax.axvline(feature.median(),color='cyan', linestyle='dashed', linewidth=2)\n",
        "  ax.set_title(col)\n",
        "plt.show()\n",
        "\n",
        "# Visualizing code of box plot for each columns to know the data distibution\n",
        "for col in dataset.describe().columns:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    dataset.boxplot( col, ax = ax)\n",
        "    ax.set_title('BoxPlot Label by ' + col)\n",
        "    #ax.set_ylabel(\"Churn\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTF1e9PwfKqa"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOYaZpKpfKqa"
      },
      "source": [
        "The histogram is a popular graphing tool. It is used to summarize discrete or continuous data that are measured on an interval scale. It is often used to illustrate the major features of the distribution of the data in a convenient form. It is also useful when dealing with large data sets (greater than 100 observations). It can help detect any unusual observations (outliers) or any gaps in the data.\n",
        "\n",
        "Thus, I used the histogram plot to analysis the variable distributions over the whole dataset whether it's symmetric or not.\n",
        "\n",
        "Box plots are used to show distributions of numeric data values, especially when you want to compare them between multiple groups. They are built to provide high-level information at a glance, offering general information about a group of data's symmetry, skew, variance, and outliers.\n",
        "\n",
        "Thus, for each numerical varibale in the given dataset, I used box plot to analyse the outliers and interquartile range including mean, median, maximum and minimum value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xrBLU6IfKqa"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrwjuBlHfKqb"
      },
      "source": [
        "The \"Connected Handling Time\" feature is symmetrically distributed, with the mean being almost the same as the median for numerical columns. However, the \"Item Price\" feature does not follow a symmetric distribution and contains noise.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiLHMWFSfKqb"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cTtRDwufKqb"
      },
      "source": [
        "Just a histogram and box plot cannot define business impact. It's done just to see the distribution of the column data over the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC_X3p0fY2L0"
      },
      "source": [
        "#### Chart - 6 - Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:02.380782Z",
          "iopub.status.busy": "2024-06-03T03:42:02.380404Z",
          "iopub.status.idle": "2024-06-03T03:42:02.809687Z",
          "shell.execute_reply": "2024-06-03T03:42:02.808719Z",
          "shell.execute_reply.started": "2024-06-03T03:42:02.380749Z"
        },
        "id": "nKTPkZZfwmCE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df[df.describe().columns.to_list()].corr()\n",
        "\n",
        "# Select only the correlation of the target variable with other features\n",
        "target_variable='CSAT Score'\n",
        "correlation_with_target = correlation_matrix[[target_variable]].sort_values(by=target_variable, ascending=False)\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_with_target, annot=True, cmap='coolwarm', cbar=True)\n",
        "plt.title(f'Correlation of {target_variable} with Independent Numerical Features')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      },
      "source": [
        "A correlation matrix is a table showing correlation coefficients between variables. Each cell in the table shows the correlation between two variables. A correlation matrix is used to summarize data, as an input into a more advanced analysis, and as a diagnostic for advanced analyses. The range of correlation is [-1,1].\n",
        "\n",
        "Thus to know the correlation between all the variables along with the correlation coeficients, i used correlation heatmap."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfSqtnDqZNRR"
      },
      "source": [
        "Based on the above correlation heatmap, we can see that \"Issue Reported,\" \"Issue Responded,\" and \"Connected Handling Time\" are moderately positively correlated with the CSAT Score.\n",
        "\n",
        "Additionally, \"Connected Handling Time\" has a positive correlation with the CSAT Score and a negative correlation with both \"Response Time\" and \"Item Price.\"\n",
        "\n",
        "All other correlations can be observed from the chart.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q29F0dvdveiT"
      },
      "source": [
        "#### Chart - 7 - Pair Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:02.812128Z",
          "iopub.status.busy": "2024-06-03T03:42:02.811757Z",
          "iopub.status.idle": "2024-06-03T03:42:12.052465Z",
          "shell.execute_reply": "2024-06-03T03:42:12.051561Z",
          "shell.execute_reply.started": "2024-06-03T03:42:02.812095Z"
        },
        "id": "o58-TEIhveiU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(df, hue=\"CSAT Score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXh0U9oCveiU"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMmPjTByveiU"
      },
      "source": [
        "Pair plot is used to understand the best set of features to explain a relationship between two variables or to form the most separated clusters. It also helps to form some simple classification models by drawing some simple lines or make linear separation in our data-set.\n",
        "\n",
        "Thus, I used pair plot to analyse the patterns of data and realationship between the features. It's exactly same as the correlation map but here you will get the graphical representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22aHeOlLveiV"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPQ8RGwHveiV"
      },
      "source": [
        "From the above chart I got to know, there are less linear relationship between variables and data points aren't linearly separable. Customers feedback data is clusetered and ovearlapped each other. connected_handling_time are quite symmetrical in nature and item_price feature and response time are quite non symmetric in nature. In this whole pair plot, the importance of response time can be seen and the connected_hanling_time with respect to different features are really insightful. Rest insights can be depicted from the above graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ATYxFrGrvw"
      },
      "source": [
        "## ***5. Hypothesis Testing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      },
      "source": [
        "### Based on your chart experiments, define two hypothetical statements from the dataset. In the next two questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7MS06SUHkB-"
      },
      "source": [
        "1. **When the Mean Response Time is less than 2, the Customer Satisfaction Score is 5.**\n",
        "2. **When the price of an item above 5660, does it result in customer satisfaction scores to go below 3**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEUt7NnHlrM"
      },
      "source": [
        "### **Hypothetical Statement - 1**\n",
        "**When the Mean Response Time is less than 2, the Customer Satisfaction Score is 5.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI9ZP0laH0D-"
      },
      "source": [
        "Null Hypothesis (H0): The mean Response Time is equal to 2 when the CSAT Score is 5.\n",
        "\n",
        "Alternative Hypothesis (H1): The mean Response Time is less than 2 when the CSAT Score is 5.\n",
        "\n",
        "Perform One-Sample t-test:\n",
        "\n",
        "We will use a one-sample t-test to compare the sample mean of Response Time against the population mean (2).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I79__PHVH19G"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:12.053825Z",
          "iopub.status.busy": "2024-06-03T03:42:12.053527Z",
          "iopub.status.idle": "2024-06-03T03:42:12.082932Z",
          "shell.execute_reply": "2024-06-03T03:42:12.081996Z",
          "shell.execute_reply.started": "2024-06-03T03:42:12.053801Z"
        },
        "id": "VHLqHrvJIsWp",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "\n",
        "\n",
        "# Step 1: Filter the data for CSAT Score of 5\n",
        "df_csat_5 = df[df['CSAT Score'] == 5]\n",
        "\n",
        "# Step 2: Calculate the mean Response Time\n",
        "mean_response_time = df_csat_5['Response_Time_seconds'].mean()\n",
        "\n",
        "# Step 3: Perform one-sample t-test\n",
        "# Null Hypothesis: Mean Response Time = 2*3600 (2 hours converted to seconds)\n",
        "hypothesized_mean = 2 * 3600  # 2 hours in seconds\n",
        "\n",
        "# Perform the t-test\n",
        "t_stat, p_value = ttest_1samp(df_csat_5['Response_Time_seconds'], hypothesized_mean)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Mean Response Time: {mean_response_time} seconds\")\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Step 4: Conclusion\n",
        "alpha = 0.05  # significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the Null Hypothesis: The mean Response Time is significantly less than 2 hours when the CSAT Score is 5.\")\n",
        "else:\n",
        "    print(\"Fail to Reject the Null Hypothesis: There is no significant evidence that the mean Response Time is less than 2 hours when the CSAT Score is 5.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou-I18pAyIpj"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2U0kk00ygSB"
      },
      "source": [
        "I have used t-Test as the statistical testing to obtain P-Value and found the result that Null hypothesis has been rejected.\n",
        "\n",
        "Based on the results of the one-sample t-test, the following findings can be made:\n",
        "\n",
        "**Mean Response Time:**\n",
        "\n",
        "The mean response time for customers who gave a CSAT Score of 5 is approximately 5706.44 seconds (about 1.58 hours).\n",
        "\n",
        "**T-statistic and P-value:**\n",
        "\n",
        "The t-statistic is -11.85, indicating that the observed mean response time is significantly different from the hypothesized mean of 7200 seconds (2 hours).\n",
        "The p-value is extremely small (2.30e-32), which is far below the significance level of 0.05.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "Given the p-value is much less than the significance level of 0.05, we reject the null hypothesis.\n",
        "\n",
        "This means there is strong statistical evidence to conclude that the mean response time for customers who rated the service with a CSAT Score of 5 is significantly less than 2 hours.\n",
        "\n",
        "**Business Implication:**\n",
        "\n",
        "The significantly lower response time for customers with a high satisfaction score suggests that prompt response times are correlated with higher customer satisfaction.\n",
        "\n",
        "Focusing on reducing response times could be a key strategy to enhance overall customer satisfaction.\n",
        "\n",
        "This analysis indicates that improving response times can positively impact customer satisfaction scores, supporting efforts to maintain or enhance quick response rates in customer service operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF3858GYyt-u"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFFfX4KQKcNj"
      },
      "source": [
        "**Rationale for Choosing the One-Sample T-Test:**\n",
        "\n",
        "**Nature of the Data:**\n",
        "\n",
        "We have a single sample of response times for customers who gave a CSAT Score of 5.\n",
        "\n",
        "We need to compare the mean of this sample to a known value (2 hours or 7200 seconds).\n",
        "\n",
        "**Continuous Variable:**\n",
        "\n",
        "Response time is a continuous variable measured in seconds.\n",
        "The t-test is suitable for comparing means of continuous data.\n",
        "\n",
        "**Comparing to a Hypothesized Value:**\n",
        "\n",
        "The one-sample t-test is designed to determine whether the sample mean is significantly different from a known or hypothesized population mean.\n",
        "In this case, we are comparing the mean response time to the hypothesized value of 7200 seconds (2 hours).\n",
        "\n",
        "**Small Sample Size or Unknown Population Variance:**\n",
        "\n",
        "If the population variance is unknown and the sample size is reasonably small, the t-test is appropriate as it accounts for sample size in its calculation.\n",
        "The t-distribution is used instead of the normal distribution when the sample size is small or the population variance is unknown.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "The one-sample t-test was chosen because it effectively tests whether the mean response time for a sample (customers who rated the service with a CSAT Score of 5) is significantly different from a specified value (2 hours). The test provides a t-statistic and p-value that help determine if the observed difference is statistically significant, thereby allowing us to make an informed conclusion regarding the hypothesis.\n",
        "\n",
        "This choice of test aligns with the objective of assessing the mean response time against a benchmark, making it a suitable and robust statistical method for this analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:12.084337Z",
          "iopub.status.busy": "2024-06-03T03:42:12.084053Z",
          "iopub.status.idle": "2024-06-03T03:42:12.638703Z",
          "shell.execute_reply": "2024-06-03T03:42:12.637680Z",
          "shell.execute_reply.started": "2024-06-03T03:42:12.084313Z"
        },
        "id": "Tz1TkC-_ZdhI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualizing the distribution of Response Time\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Histogram for Response Time\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(df['Response_Time_seconds'], bins=30, color='blue', edgecolor='black')\n",
        "plt.title('Distribution of Response Time')\n",
        "plt.xlabel('Response Time (seconds)')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Histogram for CSAT Score when it is 5\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(df[df['CSAT Score'] == 5]['Response_Time_seconds'], bins=30, color='green', edgecolor='black')\n",
        "plt.title('Distribution of Response Time (CSAT Score = 5)')\n",
        "plt.xlabel('Response Time (seconds)')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLrtcv83OEmf"
      },
      "source": [
        "### **Hypothetical Statement - 2**\n",
        "**When the price of an item above 5660, does it result in customer satisfaction scores to go below 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5djnGilGOEmg"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps8ZluDUOEmg"
      },
      "source": [
        "**Null Hypothesis (H0):** The mean CSAT score for items priced above 5660 is not significantly different from 3.\n",
        "\n",
        "**Alternative Hypothesis (H1):** The mean CSAT score for items priced above 5660 is significantly less than 3.\n",
        "\n",
        " **Test Type :** Use a one-sample t-test to compare the mean CSAT score of the filtered data to the value 3.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DADo_qtwOEmg"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:12.640755Z",
          "iopub.status.busy": "2024-06-03T03:42:12.640310Z",
          "iopub.status.idle": "2024-06-03T03:42:12.655745Z",
          "shell.execute_reply": "2024-06-03T03:42:12.654805Z",
          "shell.execute_reply.started": "2024-06-03T03:42:12.640718Z"
        },
        "id": "pNgHgcOtN7bR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "\n",
        "\n",
        "# Step 1: Filter the Data\n",
        "high_price_df = df[df['Item_price'] > 5660]\n",
        "\n",
        "# Step 2: Perform a One-Sample t-test\n",
        "# Null Hypothesis: Mean CSAT score is 3\n",
        "# Alternative Hypothesis: Mean CSAT score is less than 3\n",
        "t_stat, p_value = ttest_1samp(high_price_df['CSAT Score'], 3)\n",
        "\n",
        "# Since it's a one-tailed test, we need to divide the p-value by 2\n",
        "p_value /= 2\n",
        "\n",
        "# Check if we reject the null hypothesis\n",
        "significance_level = 0.05\n",
        "reject_null = p_value < significance_level and t_stat < 0\n",
        "\n",
        "# Print the results\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "if reject_null:\n",
        "    print(\"Reject the Null Hypothesis: The mean CSAT score for items priced above 5660 is significantly less than 3.\")\n",
        "else:\n",
        "    print(\"Fail to Reject the Null Hypothesis: There is no significant evidence that the mean CSAT score for items priced above 5660 is less than 3.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MNg8wJ1Pbkx"
      },
      "source": [
        "\n",
        "\n",
        "**Objective:** We want to compare the mean CSAT score of a subset of data (items priced above 5660) to a specific value (3).\n",
        "\n",
        "**Type of Test:** A one-sample t-test is appropriate when you are comparing the mean of a single sample to a known or hypothesized population mean.\n",
        "\n",
        "**Assumption:** The t-test assumes that the data is approximately normally distributed, which is a reasonable assumption for many real-world data sets, especially when the sample size is large."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE2e92OSP2y_"
      },
      "source": [
        "**Findings Interpretation**\n",
        "\n",
        "Fail to Reject Null Hypothesis: The p-value is greater than 0.05, it means there is not enough evidence to suggest that items priced above 5660 significantly affect customer satisfaction scores to be below 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF2oLzSdPqYh"
      },
      "source": [
        "**Explanation of Output**\n",
        "\n",
        "**T-statistic:** This value indicates how many standard deviations the sample mean is away from the hypothesized mean. A negative t-statistic would support the alternative hypothesis that the sample mean is less than the hypothesized mean.\n",
        "\n",
        "**P-value:** This value tells us the probability of obtaining a result at least as extreme as the one observed, assuming the null hypothesis is true. Since we are performing a one-tailed test, the p-value is divided by 2.\n",
        "\n",
        "**Decision Rule:** If the p-value is less than the significance level (0.05) and the t-statistic is negative, we reject the null hypothesis, indicating that the mean CSAT score for high-priced items is significantly less than 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VL2QIwzOEmh"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EZtE-psOEmh"
      },
      "source": [
        "To determine whether the price of an item above 5660 results in customer satisfaction scores below 3, I performed a one-sample t-test. Here's a detailed explanation of the choice and procedure for the test:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:12.657840Z",
          "iopub.status.busy": "2024-06-03T03:42:12.657020Z",
          "iopub.status.idle": "2024-06-03T03:42:13.355202Z",
          "shell.execute_reply": "2024-06-03T03:42:13.354218Z",
          "shell.execute_reply.started": "2024-06-03T03:42:12.657807Z"
        },
        "id": "xH-r1x7xQd75",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Visualization\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "# Histogram of CSAT Scores for high priced items\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(high_price_df['CSAT Score'], kde=True, bins=10, color='skyblue')\n",
        "plt.axvline(x=3, color='red', linestyle='--')\n",
        "plt.title('Distribution of CSAT Scores for Items Priced Above 5660')\n",
        "plt.xlabel('CSAT Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend(['Hypothesized Mean (3)', 'CSAT Scores'])\n",
        "\n",
        "# Boxplot of CSAT Scores for high priced items\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(y=high_price_df['CSAT Score'], color='skyblue')\n",
        "plt.axhline(y=3, color='red', linestyle='--')\n",
        "plt.title('Boxplot of CSAT Scores for Items Priced Above 5660')\n",
        "plt.ylabel('CSAT Score')\n",
        "plt.legend(['Hypothesized Mean (3)', 'CSAT Scores'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORCHykFwQvmo"
      },
      "source": [
        "Histogram: We create a histogram to visualize the distribution of CSAT scores for items priced above 5660. The hypothesized mean (3) is marked with a red dashed line.\n",
        "\n",
        "Boxplot: We create a boxplot to visualize the spread and central tendency of the CSAT scores. The hypothesized mean (3) is again marked with a red dashed line.\n",
        "\n",
        "These visualizations help to see how the CSAT scores are distributed around the hypothesized mean and can provide a visual confirmation of the results of the hypothesis test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLjJCtPM0KBk"
      },
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:13.356721Z",
          "iopub.status.busy": "2024-06-03T03:42:13.356400Z",
          "iopub.status.idle": "2024-06-03T03:42:13.372719Z",
          "shell.execute_reply": "2024-06-03T03:42:13.371967Z",
          "shell.execute_reply.started": "2024-06-03T03:42:13.356691Z"
        },
        "id": "nEQ5IKIFtrok",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Creating a copy of the dataset for further feature engineering\n",
        "df_new=dataset.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiyOF9F70UgQ"
      },
      "source": [
        "### 1. Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:13.374041Z",
          "iopub.status.busy": "2024-06-03T03:42:13.373755Z",
          "iopub.status.idle": "2024-06-03T03:42:14.087305Z",
          "shell.execute_reply": "2024-06-03T03:42:14.086412Z",
          "shell.execute_reply.started": "2024-06-03T03:42:13.374018Z"
        },
        "id": "iRsAHk1K0fpS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Missing Values/Null Values Count\n",
        "print(df_new.isnull().sum())\n",
        "\n",
        "# Visualizing the missing values\n",
        "\n",
        "# Step 1: Calculate the count of missing values in each column and sort in descending order\n",
        "missing_values = df_new.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "\n",
        "# Step 2: Create a horizontal bar plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x=missing_values, y=missing_values.index, orient='h')\n",
        "plt.xlabel('Count of Missing Values')\n",
        "plt.ylabel('Columns')\n",
        "plt.title('Count of Missing Values in Each Column')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wuGOrhz0itI"
      },
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oD5qHxDg2Es"
      },
      "source": [
        "We employed various missing value imputation techniques based on the nature of the features and the distribution of the data:\n",
        "\n",
        "**Order_id:** As this feature is not significant for our analysis and the number of missing values is minimal, we opted to drop this column entirely.\n",
        "\n",
        "**Customer Remarks:** With a substantial number of missing values (57165), we couldn't discard this feature as it holds crucial information. Instead, we replaced the NaN values with \"Missing Reviews\" to ensure we retain the textual data for analysis.\n",
        "\n",
        "**Categorical Column Imputation (Customer city and Product Category):** Since these categorical features are vital for our analysis, we used mode imputation to fill in the missing values. Mode imputation was chosen as it replaces missing values with the most frequently occurring category, thereby preserving the distribution of the data.\n",
        "\n",
        "**Numerical Column Imputation (connected_handling_time and item_price):** For connected_handling_time, which follows a normal distribution with minimal outliers, we applied mean imputation to replace missing values. Conversely, for item_price, where outliers are more prominent, median imputation was utilized to ensure robustness against outliers.\n",
        "\n",
        "**order_date_time:** Mode imputation was applied to handle missing values in this feature, as it represents datetime data. Subsequently, we converted it into datetime format to extract additional temporal features like day and month.\n",
        "\n",
        "These techniques were selected to effectively manage missing data while preserving the integrity and utility of the dataset for subsequent analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:14.177926Z",
          "iopub.status.busy": "2024-06-03T03:42:14.177485Z",
          "iopub.status.idle": "2024-06-03T03:42:14.438045Z",
          "shell.execute_reply": "2024-06-03T03:42:14.437226Z",
          "shell.execute_reply.started": "2024-06-03T03:42:14.177894Z"
        },
        "id": "ImHBtox9iLzP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Missing Values/Null Values Count\n",
        "print(df_new.isnull().sum())\n",
        "\n",
        "# Visualizing the missing values\n",
        "\n",
        "# Step 1: Calculate the count of missing values in each column and sort in descending order\n",
        "missing_values = df_new.isnull().sum().sort_values(ascending=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id1riN9m0vUs"
      },
      "source": [
        "### 2. Handling Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:14.439464Z",
          "iopub.status.busy": "2024-06-03T03:42:14.439179Z",
          "iopub.status.idle": "2024-06-03T03:42:14.494937Z",
          "shell.execute_reply": "2024-06-03T03:42:14.494070Z",
          "shell.execute_reply.started": "2024-06-03T03:42:14.439439Z"
        },
        "id": "M6w2CzZf04JK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# To separate the symmetric distributed features and skew symmetric distributed features\n",
        "df_new[\"CSAT Score\"]=df_new[\"CSAT Score\"].astype('str')\n",
        "symmetric_feature=[]\n",
        "non_symmetric_feature=[]\n",
        "for i in df_new.describe().columns:\n",
        "  if abs(df_new[i].mean()-df_new[i].median())<0.2:\n",
        "    symmetric_feature.append(i)\n",
        "  else:\n",
        "    non_symmetric_feature.append(i)\n",
        "\n",
        "# Getting Symmetric Distributed Features\n",
        "print(\"Symmetric Distributed Features : -\",symmetric_feature)\n",
        "\n",
        "# Getting Skew Symmetric Distributed Features\n",
        "print(\"Skew Symmetric Distributed Features : -\",non_symmetric_feature)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:14.496271Z",
          "iopub.status.busy": "2024-06-03T03:42:14.496007Z",
          "iopub.status.idle": "2024-06-03T03:42:14.501608Z",
          "shell.execute_reply": "2024-06-03T03:42:14.500570Z",
          "shell.execute_reply.started": "2024-06-03T03:42:14.496249Z"
        },
        "id": "VqJ-nKe-7sH1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# For Skew Symmetric features defining upper and lower boundry\n",
        "def outlier_treatment(df,feature):\n",
        "  upper_boundary= df[feature].mean()+3*df[feature].std()\n",
        "  lower_boundary= df[feature].mean()-3*df[feature].std()\n",
        "  return upper_boundary,lower_boundary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:14.503778Z",
          "iopub.status.busy": "2024-06-03T03:42:14.502918Z",
          "iopub.status.idle": "2024-06-03T03:42:14.518615Z",
          "shell.execute_reply": "2024-06-03T03:42:14.517658Z",
          "shell.execute_reply.started": "2024-06-03T03:42:14.503751Z"
        },
        "id": "iu4N8d5i8Jdr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Restricting the data to lower and upper boundry\n",
        "for feature in non_symmetric_feature:\n",
        "  df_new.loc[df_new[feature]<= outlier_treatment(df=df_new,feature=feature)[1], feature]=outlier_treatment(df=df_new,feature=feature)[1]\n",
        "  df_new.loc[df_new[feature]>= outlier_treatment(df=df_new,feature=feature)[0], feature]=outlier_treatment(df=df_new,feature=feature)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:14.520438Z",
          "iopub.status.busy": "2024-06-03T03:42:14.520181Z",
          "iopub.status.idle": "2024-06-03T03:42:15.840847Z",
          "shell.execute_reply": "2024-06-03T03:42:15.839905Z",
          "shell.execute_reply.started": "2024-06-03T03:42:14.520417Z"
        },
        "id": "56KLPEcOw-MQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# After Outlier Treatment showing the dataset distribution using strip plot\n",
        "# Visualising  code for the numerical columns\n",
        "for col in df_new.describe().columns:\n",
        "  fig=plt.figure(figsize=(9,6))\n",
        "  sns.stripplot(df_new[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:14.089147Z",
          "iopub.status.busy": "2024-06-03T03:42:14.088692Z",
          "iopub.status.idle": "2024-06-03T03:42:14.176162Z",
          "shell.execute_reply": "2024-06-03T03:42:14.175227Z",
          "shell.execute_reply.started": "2024-06-03T03:42:14.089108Z"
        },
        "id": "DGccVwPdhKob",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Step 1: Drop 'Order_id' column\n",
        "df_new.drop(columns=['Order_id'], inplace=True)\n",
        "\n",
        "# Step 2: Replace missing values in 'Customer Remarks' with 'Missing Reviews'\n",
        "df_new['Customer Remarks'].fillna('Missing Reviews', inplace=True)\n",
        "\n",
        "# Step 3: Impute missing values in categorical columns ('Customer city' and 'Product Category') with mode\n",
        "df_new['Customer_City'].fillna(df_new['Customer_City'].mode()[0], inplace=True)\n",
        "df_new['Product_category'].fillna(df_new['Product_category'].mode()[0], inplace=True)\n",
        "\n",
        "# Step 4: Impute missing values in numerical columns ('connected_handling_time' and 'item_price')\n",
        "# Impute 'connected_handling_time' with mean\n",
        "df_new['connected_handling_time'].fillna(df_new['connected_handling_time'].mean(), inplace=True)\n",
        "# Impute 'item_price' with median\n",
        "df_new['Item_price'].fillna(df_new['Item_price'].median(), inplace=True)\n",
        "\n",
        "# Step 5: Impute missing values in 'order_date_time' with mode\n",
        "df_new['order_date_time'].fillna(df_new['order_date_time'].mode()[0], inplace=True)\n",
        "\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify changes\n",
        "print(df_new.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "578E2V7j08f6"
      },
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUP21tsOyJjb"
      },
      "source": [
        "First I changed the CSAT Score column to sring as it shouldn't be treated as numerical column as there are only five type of values and should be treated as categorical column. Then I separated the skew symmetric and symmetric features and define the upper and lower boundry as defined below. Again, as it is a classification problem I restrict the both boundaries and I pull down the higher value restricted to the upper limit\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDVHj6krj3xX"
      },
      "source": [
        "In a Gaussian distribution while its the symmetric curve and outlier are present. Then, we can set the boundary by taking standard deviation into action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89xtkJwZ18nB"
      },
      "source": [
        "### 3. Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:15.842197Z",
          "iopub.status.busy": "2024-06-03T03:42:15.841936Z",
          "iopub.status.idle": "2024-06-03T03:42:15.987255Z",
          "shell.execute_reply": "2024-06-03T03:42:15.986141Z",
          "shell.execute_reply.started": "2024-06-03T03:42:15.842175Z"
        },
        "id": "pkGOh3drqrDc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_new.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:15.988623Z",
          "iopub.status.busy": "2024-06-03T03:42:15.988344Z",
          "iopub.status.idle": "2024-06-03T03:42:16.015361Z",
          "shell.execute_reply": "2024-06-03T03:42:16.014535Z",
          "shell.execute_reply.started": "2024-06-03T03:42:15.988600Z"
        },
        "id": "tYUDjg9AqAYb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_new.drop(columns='Unique id', inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:16.016728Z",
          "iopub.status.busy": "2024-06-03T03:42:16.016443Z",
          "iopub.status.idle": "2024-06-03T03:42:16.053856Z",
          "shell.execute_reply": "2024-06-03T03:42:16.052929Z",
          "shell.execute_reply.started": "2024-06-03T03:42:16.016705Z"
        },
        "id": "21JmIYMG2hEo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# Encode your categorical columns\n",
        "# Getting the categorical columns\n",
        "df_new[\"CSAT Score\"]=df_new[\"CSAT Score\"].astype('int')\n",
        "categorical_columns=list(set(df_new.columns.to_list()).difference(set(df_new.describe().columns.to_list())))\n",
        "non_cat_columns=['issue_responded','order_date_time','Issue_reported at','Survey_response_Date','Customer Remarks']\n",
        "categorical_columns = list(set(categorical_columns) - set(non_cat_columns))\n",
        "print(\"Categorical Columns are :-\", categorical_columns, \" :- \", len(categorical_columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:16.055288Z",
          "iopub.status.busy": "2024-06-03T03:42:16.054995Z",
          "iopub.status.idle": "2024-06-03T03:42:16.434618Z",
          "shell.execute_reply": "2024-06-03T03:42:16.433620Z",
          "shell.execute_reply.started": "2024-06-03T03:42:16.055263Z"
        },
        "id": "axarb3YM1yvY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Perform one-hot encoding\n",
        "df_encoded = pd.get_dummies(df_new, columns=categorical_columns)\n",
        "\n",
        "# Display the encoded DataFrame\n",
        "df_encoded.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67NQN5KX2AMe"
      },
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDaue5h32n_G"
      },
      "source": [
        "I have used One Hot Encoding for all the categorical features,because these features are likely nominal categorical variables, meaning there is no inherent order or ranking among the categories. For these variables, it would be appropriate to apply one-hot encoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      },
      "source": [
        "### 4. Feature Manipulation & Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C74aWNz2AliB"
      },
      "source": [
        "#### 1. Feature Manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NKywcI3So33"
      },
      "source": [
        "Created Some new features like Response_Time_seconds,day_number_order_date,weekday_number_order_date,weekday_num_response_date and day_num_response_date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:16.436169Z",
          "iopub.status.busy": "2024-06-03T03:42:16.435865Z",
          "iopub.status.idle": "2024-06-03T03:42:17.328536Z",
          "shell.execute_reply": "2024-06-03T03:42:17.327529Z",
          "shell.execute_reply.started": "2024-06-03T03:42:16.436144Z"
        },
        "id": "Y8wIU7H9vwUa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Ensure the 'Issue reported at' and 'Issue responded' columns are in datetime format\n",
        "df_encoded['Issue_reported at'] = pd.to_datetime(df_encoded['Issue_reported at'], format='%d/%m/%Y %H:%M')\n",
        "df_encoded['issue_responded'] = pd.to_datetime(df_encoded['issue_responded'], format='%d/%m/%Y %H:%M')\n",
        "\n",
        "\n",
        "# Create a new feature the response time\n",
        "df_encoded['Response_Time'] = df_encoded['issue_responded'] - df_encoded['Issue_reported at']\n",
        "\n",
        "# Convert 'Response_Time' to a numerical format in seconds for aggregation\n",
        "df_encoded['Response_Time_seconds'] = df_encoded['Response_Time'].dt.total_seconds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:17.330492Z",
          "iopub.status.busy": "2024-06-03T03:42:17.330126Z",
          "iopub.status.idle": "2024-06-03T03:42:17.446475Z",
          "shell.execute_reply": "2024-06-03T03:42:17.445525Z",
          "shell.execute_reply.started": "2024-06-03T03:42:17.330457Z"
        },
        "id": "2i-dR56MwCYg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Convert order_date_time to datetime\n",
        "df_encoded['order_date_time'] = pd.to_datetime(df_encoded['order_date_time'], format='%d/%m/%Y %H:%M')\n",
        "\n",
        "# Extract day number (day of the month)\n",
        "df_encoded['day_number_order_date'] = df_encoded['order_date_time'].dt.day\n",
        "\n",
        "# Extract weekday (numerical value: 0 for Sunday, 1 for Monday, etc.)\n",
        "df_encoded['weekday_num_order_date'] = df_encoded['order_date_time'].dt.weekday + 1  # Monday=1, Sunday=7\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Convert 'Survey_response_Date' to datetime format\n",
        "df_encoded['Survey_response_Date'] = pd.to_datetime(df_encoded['Survey_response_Date'], format='%d-%b-%y')\n",
        "\n",
        "# Extract day number (day of the month)\n",
        "df_encoded['day_number_response_date'] = df_encoded['Survey_response_Date'].dt.day\n",
        "\n",
        "# Extract weekday (numerical value: 0 for Sunday, 1 for Monday, etc.)\n",
        "df_encoded['weekday_num_response_date'] = df_encoded['Survey_response_Date'].dt.weekday + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:17.447838Z",
          "iopub.status.busy": "2024-06-03T03:42:17.447543Z",
          "iopub.status.idle": "2024-06-03T03:42:17.551022Z",
          "shell.execute_reply": "2024-06-03T03:42:17.549975Z",
          "shell.execute_reply.started": "2024-06-03T03:42:17.447813Z"
        },
        "id": "ZrPODWG2bZB4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Drop Date columns after feature extraction\n",
        "df_encoded.drop(columns=['order_date_time', 'Survey_response_Date','Issue_reported at','issue_responded','Response_Time'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:17.552658Z",
          "iopub.status.busy": "2024-06-03T03:42:17.552364Z",
          "iopub.status.idle": "2024-06-03T03:42:17.579893Z",
          "shell.execute_reply": "2024-06-03T03:42:17.578923Z",
          "shell.execute_reply.started": "2024-06-03T03:42:17.552622Z"
        },
        "id": "fkJniPCwdux5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_encoded.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DejudWSA-a0"
      },
      "source": [
        "#### 2. Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:17.581473Z",
          "iopub.status.busy": "2024-06-03T03:42:17.581077Z",
          "iopub.status.idle": "2024-06-03T03:42:17.587613Z",
          "shell.execute_reply": "2024-06-03T03:42:17.586619Z",
          "shell.execute_reply.started": "2024-06-03T03:42:17.581427Z"
        },
        "id": "PLWgA-MabkJR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Checking the shape of dataset\n",
        "df_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:17.589376Z",
          "iopub.status.busy": "2024-06-03T03:42:17.589018Z",
          "iopub.status.idle": "2024-06-03T03:42:17.596766Z",
          "shell.execute_reply": "2024-06-03T03:42:17.596027Z",
          "shell.execute_reply.started": "2024-06-03T03:42:17.589345Z"
        },
        "id": "9VRjOWckytqe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dropping Constant and Quasi Constant Feature\n",
        "def dropping_constant(data):\n",
        "    from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "    # Drop non-numeric columns\n",
        "    numeric_data = data.select_dtypes(include=['number'])\n",
        "\n",
        "    var_thres = VarianceThreshold(threshold=0.05)\n",
        "    var_thres.fit(numeric_data)\n",
        "\n",
        "    concol = [column for column in numeric_data.columns\n",
        "              if column not in numeric_data.columns[var_thres.get_support()]]\n",
        "\n",
        "    if \"CSAT Score\" in concol:\n",
        "        concol.remove(\"CSAT Score\")\n",
        "\n",
        "    df_removed_var = data.drop(concol, axis=1)\n",
        "    return df_removed_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:17.598498Z",
          "iopub.status.busy": "2024-06-03T03:42:17.598011Z",
          "iopub.status.idle": "2024-06-03T03:42:17.952457Z",
          "shell.execute_reply": "2024-06-03T03:42:17.951323Z",
          "shell.execute_reply.started": "2024-06-03T03:42:17.598472Z"
        },
        "id": "m76C7i9Ebx5o",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Calling the function\n",
        "df_removed_var=dropping_constant(df_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:17.954680Z",
          "iopub.status.busy": "2024-06-03T03:42:17.954300Z",
          "iopub.status.idle": "2024-06-03T03:42:17.960848Z",
          "shell.execute_reply": "2024-06-03T03:42:17.959766Z",
          "shell.execute_reply.started": "2024-06-03T03:42:17.954634Z"
        },
        "id": "2037ugSmblqz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Checking the shape after feature dropped\n",
        "df_removed_var.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:17.962404Z",
          "iopub.status.busy": "2024-06-03T03:42:17.962111Z",
          "iopub.status.idle": "2024-06-03T03:42:18.482686Z",
          "shell.execute_reply": "2024-06-03T03:42:18.481714Z",
          "shell.execute_reply.started": "2024-06-03T03:42:17.962381Z"
        },
        "id": "UeSGoW4V0LOm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Drop non-numeric columns\n",
        "numeric_data = df_removed_var.select_dtypes(include=['number'])\n",
        "numeric_data.drop(columns=['CSAT Score'], inplace=True)\n",
        "corr = numeric_data.corr()\n",
        "cmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)\n",
        "\n",
        "\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:18.484255Z",
          "iopub.status.busy": "2024-06-03T03:42:18.483944Z",
          "iopub.status.idle": "2024-06-03T03:42:33.672365Z",
          "shell.execute_reply": "2024-06-03T03:42:33.669839Z",
          "shell.execute_reply.started": "2024-06-03T03:42:18.484228Z"
        },
        "id": "jjKkr7TC1XC3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install statsmodels\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_vif(df):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Feature\"] = numeric_data.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(numeric_data.values, i) for i in range(numeric_data.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "# Assuming df is your DataFrame containing the features\n",
        "vif_results = calculate_vif(df)\n",
        "print(vif_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:33.677091Z",
          "iopub.status.busy": "2024-06-03T03:42:33.675309Z",
          "iopub.status.idle": "2024-06-03T03:42:33.859403Z",
          "shell.execute_reply": "2024-06-03T03:42:33.858368Z",
          "shell.execute_reply.started": "2024-06-03T03:42:33.676908Z"
        },
        "id": "u3hfIGLq4ZUL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Drop highly correlated feature\n",
        "df_removed_var.drop(columns=['weekday_num_order_date'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:33.861238Z",
          "iopub.status.busy": "2024-06-03T03:42:33.860943Z",
          "iopub.status.idle": "2024-06-03T03:42:33.869240Z",
          "shell.execute_reply": "2024-06-03T03:42:33.868284Z",
          "shell.execute_reply.started": "2024-06-03T03:42:33.861214Z"
        },
        "id": "_RD2Mq1SAZM_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Check Feature Correlation and finding multicolinearity\n",
        "def correlation(df,threshold):\n",
        "  col_corr=set()\n",
        "  corr_matrix= df.corr()\n",
        "  for i in range (len(corr_matrix.columns)):\n",
        "    for j in range(i):\n",
        "      if abs (corr_matrix.iloc[i,j])>threshold:\n",
        "        colname=corr_matrix.columns[i]\n",
        "        col_corr.add(colname)\n",
        "  return list(col_corr)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:33.870766Z",
          "iopub.status.busy": "2024-06-03T03:42:33.870433Z",
          "iopub.status.idle": "2024-06-03T03:42:33.996072Z",
          "shell.execute_reply": "2024-06-03T03:42:33.994852Z",
          "shell.execute_reply.started": "2024-06-03T03:42:33.870743Z"
        },
        "id": "f2HYgia8TCCa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Getting multicolinear columns and dropping them\n",
        "numeric_data = df_removed_var.select_dtypes(include=['number'])\n",
        "numeric_data.drop(columns=['CSAT Score'], inplace=True)\n",
        "highly_correlated_columns=correlation(numeric_data,0.5)\n",
        "\n",
        "if \"CSAT Score\" in highly_correlated_columns:\n",
        "  highly_correlated_columns.remove(\"CSAT Score\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "df_removed=df_removed_var.drop(highly_correlated_columns,axis=1)\n",
        "df_removed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:33.999563Z",
          "iopub.status.busy": "2024-06-03T03:42:33.998538Z",
          "iopub.status.idle": "2024-06-03T03:42:34.316707Z",
          "shell.execute_reply": "2024-06-03T03:42:34.315241Z",
          "shell.execute_reply.started": "2024-06-03T03:42:33.999528Z"
        },
        "id": "PGMxgebo5goC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def calculate_vif(df):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Feature\"] = numeric_data.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(numeric_data.values, i) for i in range(numeric_data.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "# Assuming df is your DataFrame containing the features\n",
        "vif_results = calculate_vif(df)\n",
        "print(vif_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:34.325133Z",
          "iopub.status.busy": "2024-06-03T03:42:34.323269Z",
          "iopub.status.idle": "2024-06-03T03:42:34.340389Z",
          "shell.execute_reply": "2024-06-03T03:42:34.338888Z",
          "shell.execute_reply.started": "2024-06-03T03:42:34.325081Z"
        },
        "id": "T7_-rO-0fi9D",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# After Feature Selection checking the shape left with\n",
        "df_removed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:34.359844Z",
          "iopub.status.busy": "2024-06-03T03:42:34.348708Z",
          "iopub.status.idle": "2024-06-03T03:42:34.649183Z",
          "shell.execute_reply": "2024-06-03T03:42:34.647619Z",
          "shell.execute_reply.started": "2024-06-03T03:42:34.359794Z"
        },
        "id": "kr_li8kLPv96",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_removed.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEMng2IbBLp7"
      },
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_syLORmZO_j"
      },
      "source": [
        "I used Dropping Constant Feature, Dropping columns having multicolinearity and validate through VIF.\n",
        "\n",
        "Feature Selector that removes all low variance features. This feature selection algorithm looks only at the features(X), not the desired outputs(Y), and can be used for unsupported learning.\n",
        "\n",
        "A Pearson correlation is a number between -1 and 1 that indicates the extent to which two variables are linearly related. The Pearson correlation is also known as the product moment correlation coefficient (PMCC) or simply correlation\n",
        "\n",
        "Pearson correlations are suitable only for metric variables The correlation coefficient has values between -1 to 1\n",
        "\n",
        " A value closer to 0 implies weaker correlation (exact 0 implying no correlation)\n",
        "\n",
        " A value closer to 1 implies stronger positive correlation\n",
        "\n",
        " A value closer to -1 implies stronger negative correlation\n",
        "\n",
        "Collinearity is the state where two variables are highly correlated and contain similar information about the variance within a given dataset. To detect collinearity among variables, simply create a correlation matrix and find variables with large absolute values.\n",
        "\n",
        "Steps for Implementing VIF\n",
        "\n",
        " Calculate the VIF factors.\n",
        "\n",
        " Inspect the factors for each predictor variable, if the VIF is between 510, multicollinearity is likely present and you should consider dropping the variable.\n",
        "\n",
        "In VIF method, we pick each feature and regress it against all of the other features. For each regression, the factor is calculated as :\n",
        "\n",
        "VIF=\\frac{1}{1-R^2}\n",
        "\n",
        "Where, R-squared is the coefficient of determination in linear regression. Its value lies between 0 and 1.\n",
        "\n",
        "1st I dropped columns having constant or quasi constant variance. Then using pearson corelation I removed the columns having multicolinearity and again validate the VIFs for each feauture and found some features having VIF of more than 5-10 and I considered it to be 8 and again manipulated some features and again dropped multicolinear columns to make the VIF less than 8. The features got decreased from 77 to 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      },
      "source": [
        "##### Which all features you found important and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNVZ9zx19K6k"
      },
      "source": [
        "### 5. Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:34.652178Z",
          "iopub.status.busy": "2024-06-03T03:42:34.651774Z",
          "iopub.status.idle": "2024-06-03T03:42:34.699491Z",
          "shell.execute_reply": "2024-06-03T03:42:34.698533Z",
          "shell.execute_reply.started": "2024-06-03T03:42:34.652126Z"
        },
        "id": "YnvslXZKj5dH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Getting symmetric and skew symmetric features from the cplumns\n",
        "symmetric_feature=[]\n",
        "non_symmetric_feature=[]\n",
        "for i in df_removed.describe().columns:\n",
        "  if abs(df_removed[i].mean()-df_removed[i].median())<0.25:\n",
        "    symmetric_feature.append(i)\n",
        "  else:\n",
        "    non_symmetric_feature.append(i)\n",
        "\n",
        "# Getting Symmetric Distributed Features\n",
        "print(\"Symmetric Distributed Features : -\",symmetric_feature)\n",
        "# Removing Customer Service Calls column from the list as it's an important factor\n",
        "# which can't be treated as outliers here will is already leading to higher churn as we have seen furing analysis.\n",
        "non_symmetric_feature.remove('CSAT Score')\n",
        "\n",
        "# Getting Skew Symmetric Distributed Features\n",
        "print(\"Skew Symmetric Distributed Features : -\",non_symmetric_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqoHp30x9hH9"
      },
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TneQ8rvbLtBr"
      },
      "source": [
        "From the features, I got to know that there are 2 features which aren't symmetric so aren't following gaussian distribution and rest are having szymmetric curve. Thus, for those two columns I have used Exponential transformation to achieve gaussian distribution.\n",
        "\n",
        " I tried with other transformations and found exponetial tranformation with no infinity value and working fine. So, I am continuing with Exponentia lransformation with a power of 0.25.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k6xA1sJN8S1"
      },
      "source": [
        "**First Transformation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:34.701189Z",
          "iopub.status.busy": "2024-06-03T03:42:34.700898Z",
          "iopub.status.idle": "2024-06-03T03:42:34.710415Z",
          "shell.execute_reply": "2024-06-03T03:42:34.709437Z",
          "shell.execute_reply.started": "2024-06-03T03:42:34.701165Z"
        },
        "id": "sac3ukURl6CW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Transform Your data\n",
        "# Exponential Transforming the required column\n",
        "df_removed['Item_price']=np.sqrt(df_removed['Item_price'])\n",
        "df_removed['Response_Time_seconds']=np.sqrt(df_removed['Response_Time_seconds'])\n",
        "df_removed['day_number_order_date']=(df_removed['day_number_order_date'])**0.25\n",
        "df_removed['day_number_response_date']=(df_removed['day_number_response_date'])**0.25\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:34.711873Z",
          "iopub.status.busy": "2024-06-03T03:42:34.711568Z",
          "iopub.status.idle": "2024-06-03T03:42:34.956352Z",
          "shell.execute_reply": "2024-06-03T03:42:34.955350Z",
          "shell.execute_reply.started": "2024-06-03T03:42:34.711850Z"
        },
        "id": "BSAauNZrQNpw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_removed.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:34.957929Z",
          "iopub.status.busy": "2024-06-03T03:42:34.957580Z",
          "iopub.status.idle": "2024-06-03T03:42:34.966873Z",
          "shell.execute_reply": "2024-06-03T03:42:34.965702Z",
          "shell.execute_reply.started": "2024-06-03T03:42:34.957904Z"
        },
        "id": "VVa7Y8MFQsct",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Fill NaN values with the median of Response_Time_seconds columns\n",
        "df_removed['Response_Time_seconds'] = df_removed['Response_Time_seconds'].fillna(df_removed['Response_Time_seconds'].median())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:34.968947Z",
          "iopub.status.busy": "2024-06-03T03:42:34.968513Z",
          "iopub.status.idle": "2024-06-03T03:42:35.023086Z",
          "shell.execute_reply": "2024-06-03T03:42:35.022075Z",
          "shell.execute_reply.started": "2024-06-03T03:42:34.968913Z"
        },
        "id": "xbjk7nAfFjWX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Getting symmetric and skew symmetric features from the cplumns\n",
        "symmetric_feature=[]\n",
        "non_symmetric_feature=[]\n",
        "for i in df_removed.describe().columns:\n",
        "  if abs(df_removed[i].mean()-df_removed[i].median())<0.25:\n",
        "    symmetric_feature.append(i)\n",
        "  else:\n",
        "    non_symmetric_feature.append(i)\n",
        "\n",
        "# Getting Symmetric Distributed Features\n",
        "print(\"Symmetric Distributed Features : -\",symmetric_feature)\n",
        "# Removing Customer Service Calls column from the list as it's an important factor\n",
        "# which can't be treated as outliers here will is already leading to higher churn as we have seen furing analysis.\n",
        "non_symmetric_feature.remove('CSAT Score')\n",
        "\n",
        "# Getting Skew Symmetric Distributed Features\n",
        "print(\"Skew Symmetric Distributed Features : -\",non_symmetric_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8Wrr1HIOCHs"
      },
      "source": [
        "**Second Transformation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:35.024671Z",
          "iopub.status.busy": "2024-06-03T03:42:35.024348Z",
          "iopub.status.idle": "2024-06-03T03:42:35.030390Z",
          "shell.execute_reply": "2024-06-03T03:42:35.029457Z",
          "shell.execute_reply.started": "2024-06-03T03:42:35.024624Z"
        },
        "id": "Y4Z5lNTpGLXE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_removed['Response_Time_seconds'] = np.sqrt(df_removed['Response_Time_seconds'])\n",
        "df_removed['Item_price'] = (df_removed['Item_price'])**0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:35.049040Z",
          "iopub.status.busy": "2024-06-03T03:42:35.048694Z",
          "iopub.status.idle": "2024-06-03T03:42:35.097328Z",
          "shell.execute_reply": "2024-06-03T03:42:35.096329Z",
          "shell.execute_reply.started": "2024-06-03T03:42:35.049015Z"
        },
        "id": "z3_Ui1H-GYaq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Getting symmetric and skew symmetric features from the cplumns\n",
        "symmetric_feature=[]\n",
        "non_symmetric_feature=[]\n",
        "for i in df_removed.describe().columns:\n",
        "  if abs(df_removed[i].mean()-df_removed[i].median())<0.25:\n",
        "    symmetric_feature.append(i)\n",
        "  else:\n",
        "    non_symmetric_feature.append(i)\n",
        "\n",
        "# Getting Symmetric Distributed Features\n",
        "print(\"Symmetric Distributed Features : -\",symmetric_feature)\n",
        "# Removing Customer Service Calls column from the list as it's an important factor\n",
        "# which can't be treated as outliers here will is already leading to higher churn as we have seen furing analysis.\n",
        "non_symmetric_feature.remove('CSAT Score')\n",
        "\n",
        "# Getting Skew Symmetric Distributed Features\n",
        "print(\"Skew Symmetric Distributed Features : -\",non_symmetric_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyhubR3sOJtQ"
      },
      "source": [
        "**Third Transformation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:35.099517Z",
          "iopub.status.busy": "2024-06-03T03:42:35.098814Z",
          "iopub.status.idle": "2024-06-03T03:42:35.104508Z",
          "shell.execute_reply": "2024-06-03T03:42:35.103626Z",
          "shell.execute_reply.started": "2024-06-03T03:42:35.099482Z"
        },
        "id": "wsOd9la4GmaJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Perform sqrt transform on 'Response_Time_seconds' column\n",
        "df_removed['Response_Time_seconds'] = np.sqrt(df_removed['Response_Time_seconds'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:35.105992Z",
          "iopub.status.busy": "2024-06-03T03:42:35.105678Z",
          "iopub.status.idle": "2024-06-03T03:42:35.155059Z",
          "shell.execute_reply": "2024-06-03T03:42:35.154071Z",
          "shell.execute_reply.started": "2024-06-03T03:42:35.105969Z"
        },
        "id": "qcplCg-fGueS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Getting symmetric and skew symmetric features from the cplumns\n",
        "symmetric_feature=[]\n",
        "non_symmetric_feature=[]\n",
        "for i in df_removed.describe().columns:\n",
        "  if abs(df_removed[i].mean()-df_removed[i].median())<0.25:\n",
        "    symmetric_feature.append(i)\n",
        "  else:\n",
        "    non_symmetric_feature.append(i)\n",
        "\n",
        "# Getting Symmetric Distributed Features\n",
        "print(\"Symmetric Distributed Features : -\",symmetric_feature)\n",
        "# Removing Customer Service Calls column from the list as it's an important factor\n",
        "# which can't be treated as outliers here will is already leading to higher churn as we have seen furing analysis.\n",
        "non_symmetric_feature.remove('CSAT Score')\n",
        "\n",
        "# Getting Skew Symmetric Distributed Features\n",
        "print(\"Skew Symmetric Distributed Features : -\",non_symmetric_feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:35.156912Z",
          "iopub.status.busy": "2024-06-03T03:42:35.156460Z",
          "iopub.status.idle": "2024-06-03T03:42:39.538656Z",
          "shell.execute_reply": "2024-06-03T03:42:39.537749Z",
          "shell.execute_reply.started": "2024-06-03T03:42:35.156863Z"
        },
        "id": "zdFioDnFkscQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Visualizing code of hist plot for each columns to know the data distibution\n",
        "for col in df_removed.loc[:,symmetric_feature]:\n",
        "  fig=plt.figure(figsize=(9,6))\n",
        "  ax=fig.gca()\n",
        "  feature= (df_removed[col])\n",
        "  sns.distplot(df_removed[col])\n",
        "  ax.axvline(feature.mean(),color='magenta', linestyle='dashed', linewidth=2)\n",
        "  ax.axvline(feature.median(),color='cyan', linestyle='dashed', linewidth=2)\n",
        "  ax.set_title(col)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMDnDkt2B6du"
      },
      "source": [
        "### 6. Data Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_-SaQemdYeu"
      },
      "source": [
        "When you are using an algorithm that assumes your features have a similar range, you should use feature scaling.\n",
        "\n",
        "If the ranges of your features differ much then you should use feature scaling. If the range does not vary a lot like one of them is between 0 and 2 and the other one is between -1 and 0.5 then you can leave them as it's. However, you should use feature scaling if the ranges are, for example, between -2 and 2 and between -100 and 100.\n",
        "\n",
        "Use Standardization when your data follows Gaussian distribution.\n",
        "Use Normalization when your data does not follow Gaussian distribution.\n",
        "\n",
        "So, in my dataset we are having large data difference and following gaussian distribution. That's why, I have used standardization using Standardscaler.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:39.540242Z",
          "iopub.status.busy": "2024-06-03T03:42:39.539917Z",
          "iopub.status.idle": "2024-06-03T03:42:39.568470Z",
          "shell.execute_reply": "2024-06-03T03:42:39.567534Z",
          "shell.execute_reply.started": "2024-06-03T03:42:39.540204Z"
        },
        "id": "dL9LWpySC6x_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Scaling your data\n",
        "# Checking the data\n",
        "df_removed.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiiVWRdJDDil"
      },
      "source": [
        "##### Which method have you used to scale you data and why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:39.570320Z",
          "iopub.status.busy": "2024-06-03T03:42:39.569899Z",
          "iopub.status.idle": "2024-06-03T03:42:39.873614Z",
          "shell.execute_reply": "2024-06-03T03:42:39.872524Z",
          "shell.execute_reply.started": "2024-06-03T03:42:39.570285Z"
        },
        "id": "5tFjtjMXVzCK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "final_df=df_removed.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:39.875236Z",
          "iopub.status.busy": "2024-06-03T03:42:39.874911Z",
          "iopub.status.idle": "2024-06-03T03:42:39.879682Z",
          "shell.execute_reply": "2024-06-03T03:42:39.878708Z",
          "shell.execute_reply.started": "2024-06-03T03:42:39.875210Z"
        },
        "id": "FL9z4CopWyT6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y=df_removed['CSAT Score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:39.895914Z",
          "iopub.status.busy": "2024-06-03T03:42:39.895620Z",
          "iopub.status.idle": "2024-06-03T03:42:39.996590Z",
          "shell.execute_reply": "2024-06-03T03:42:39.995828Z",
          "shell.execute_reply.started": "2024-06-03T03:42:39.895890Z"
        },
        "id": "jpEgHwGeXDKC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_removed.drop(columns=['CSAT Score'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:39.997979Z",
          "iopub.status.busy": "2024-06-03T03:42:39.997691Z",
          "iopub.status.idle": "2024-06-03T03:42:40.025191Z",
          "shell.execute_reply": "2024-06-03T03:42:40.024126Z",
          "shell.execute_reply.started": "2024-06-03T03:42:39.997955Z"
        },
        "trusted": true,
        "id": "SBJ5vgj4LtB3"
      },
      "outputs": [],
      "source": [
        "df_removed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:40.026743Z",
          "iopub.status.busy": "2024-06-03T03:42:40.026437Z",
          "iopub.status.idle": "2024-06-03T03:42:40.078433Z",
          "shell.execute_reply": "2024-06-03T03:42:40.077502Z",
          "shell.execute_reply.started": "2024-06-03T03:42:40.026719Z"
        },
        "id": "UwNwBsSjVnwE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Select only the numerical columns from df_removed\n",
        "numerical_columns = df_removed.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply the scaler to the numerical columns\n",
        "df_removed[numerical_columns] = scaler.fit_transform(df_removed[numerical_columns])\n",
        "\n",
        "# Save the fitted scaler\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "# Display the scaled DataFrame\n",
        "df_removed.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:40.079830Z",
          "iopub.status.busy": "2024-06-03T03:42:40.079527Z",
          "iopub.status.idle": "2024-06-03T03:42:40.085881Z",
          "shell.execute_reply": "2024-06-03T03:42:40.085000Z",
          "shell.execute_reply.started": "2024-06-03T03:42:40.079806Z"
        },
        "trusted": true,
        "id": "hJXOcWp-LtB5"
      },
      "outputs": [],
      "source": [
        "numerical_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:40.087288Z",
          "iopub.status.busy": "2024-06-03T03:42:40.087026Z",
          "iopub.status.idle": "2024-06-03T03:42:40.099386Z",
          "shell.execute_reply": "2024-06-03T03:42:40.098560Z",
          "shell.execute_reply.started": "2024-06-03T03:42:40.087266Z"
        },
        "trusted": true,
        "id": "80ulL01nLtB6"
      },
      "outputs": [],
      "source": [
        "# Save the fitted scaler\n",
        "joblib.dump(scaler, \"scaler.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "-QzvwkazLtB7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:42:40.101357Z",
          "iopub.status.busy": "2024-06-03T03:42:40.100564Z",
          "iopub.status.idle": "2024-06-03T03:42:40.336237Z",
          "shell.execute_reply": "2024-06-03T03:42:40.335248Z",
          "shell.execute_reply.started": "2024-06-03T03:42:40.101326Z"
        },
        "id": "ygyUGCuzPjZt",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_removed.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhH2vgX9EjGr"
      },
      "source": [
        "### 7. Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_removed.drop(columns=['Customer Remarks'],inplace=True)"
      ],
      "metadata": {
        "id": "bjQ0bo8DqukQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:43:00.440483Z",
          "iopub.status.busy": "2024-06-03T03:43:00.440218Z",
          "iopub.status.idle": "2024-06-03T03:43:00.452481Z",
          "shell.execute_reply": "2024-06-03T03:43:00.451672Z",
          "shell.execute_reply.started": "2024-06-03T03:43:00.440461Z"
        },
        "trusted": true,
        "id": "LohDAt_2LtB9"
      },
      "outputs": [],
      "source": [
        "#One Hot Encoding of Target Variable\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Extract the target variable\n",
        "y = final_df['CSAT Score'].values.reshape(-1, 1)\n",
        "\n",
        "# Initialize the OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Fit and transform the target variable\n",
        "y_one_hot = encoder.fit_transform(y)\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "y_one_hot_df = pd.DataFrame(y_one_hot, columns=[f'class_{int(i)}' for i in range(y_one_hot.shape[1])])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:43:00.454089Z",
          "iopub.status.busy": "2024-06-03T03:43:00.453747Z",
          "iopub.status.idle": "2024-06-03T03:43:00.918828Z",
          "shell.execute_reply": "2024-06-03T03:43:00.917818Z",
          "shell.execute_reply.started": "2024-06-03T03:43:00.454055Z"
        },
        "trusted": true,
        "id": "yMMuQtB4LtB-"
      },
      "outputs": [],
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        " # split into 70:30 ratio\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_removed,y_one_hot_df, test_size = 0.3, random_state = 0)\n",
        "\n",
        "# describes info about train and test set\n",
        "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
        "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
        "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
        "print(\"Number transactions y_test dataset: \", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:43:00.920868Z",
          "iopub.status.busy": "2024-06-03T03:43:00.920178Z",
          "iopub.status.idle": "2024-06-03T03:43:00.949809Z",
          "shell.execute_reply": "2024-06-03T03:43:00.948874Z",
          "shell.execute_reply.started": "2024-06-03T03:43:00.920830Z"
        },
        "trusted": true,
        "id": "7SYS6lC4LtB-"
      },
      "outputs": [],
      "source": [
        "features_list=X_train.columns.to_list()\n",
        "import joblib\n",
        "# Save the fitted scaler\n",
        "joblib.dump(features_list, \"features.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjKvONjwE8ra"
      },
      "source": [
        "##### What data splitting ratio have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      },
      "source": [
        "There are two competing concerns: with less training data, your parameter estimates have greater variance. With less testing data, your performance statistic will have greater variance. Broadly speaking you should be concerned with dividing data such that neither variance is too high, which is more to do with the absolute number of instances in each category rather than the percentage.\n",
        "\n",
        "If you have a total of 100 instances, you're probably stuck with cross validation as no single split is going to give you satisfactory variance in your estimates. If you have 100,000 instances, it doesn't really matter whether you choose an 80:20 split or a 90:10 split (indeed you may choose to use less training data if your method is particularly computationally intensive).\n",
        "\n",
        "You'd be surprised to find out that 80/20 is quite a commonly occurring ratio, often referred to as the Pareto principle. It's usually a safe bet if you use that ratio.\n",
        "\n",
        "In this case the training dataset is small, that's why I have taken 70:30 ratio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1XJ9OREExlT"
      },
      "source": [
        "### 8. Handling Imbalanced Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:43:00.951249Z",
          "iopub.status.busy": "2024-06-03T03:43:00.950991Z",
          "iopub.status.idle": "2024-06-03T03:43:01.120031Z",
          "shell.execute_reply": "2024-06-03T03:43:01.118583Z",
          "shell.execute_reply.started": "2024-06-03T03:43:00.951227Z"
        },
        "id": "nWaf9g7F3ZRX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Chart - 1 visualization code\n",
        "# Dependant Column Value Counts\n",
        "print(y_train.value_counts())\n",
        "print(\" \")\n",
        "# Dependant Variable Column Visualization\n",
        "y_train.value_counts().plot(kind='pie',\n",
        "                              figsize=(15,6),\n",
        "                               labels=['5','1','4','3','2']\n",
        "\n",
        "\n",
        "                              )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOzZv6IFROw"
      },
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeKDIv7pFgcC"
      },
      "source": [
        "Imbalanced dataset is relevant primarily in the context of supervised machine learning involving two or more classes.\n",
        "\n",
        "Imbalance means that the number of data points available for different the classes is different:\n",
        "If there are two classes, then balanced data would mean 50% points for each of the class. For most machine learning techniques, little imbalance is not a problem. So, if there are 60% points for one class and 40% for the other class, it should not cause any significant performance degradation. Only when the class imbalance is high, e.g. 90% points for one class and 10% for the other, standard optimization criteria or performance measures may not be as effective and would need modification.\n",
        "\n",
        "In our case the dataset dependent column data ratio is 85:15. So, during model creating it's obvios that there will be bias and having a great chance of predicting the majority one so frequently. SO the dataset should be balanced before it going for the model creation part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:43:01.122731Z",
          "iopub.status.busy": "2024-06-03T03:43:01.122011Z",
          "iopub.status.idle": "2024-06-03T03:43:14.640011Z",
          "shell.execute_reply": "2024-06-03T03:43:14.638998Z",
          "shell.execute_reply.started": "2024-06-03T03:43:01.122682Z"
        },
        "id": "hS6xePZNTal1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalance in the Target Variable using S.M.O.T.E\n",
        "\n",
        "# Convert the one-hot encoded DataFrame back to a Series of original class labels to apply SMOTE\n",
        "y_series = y_train.idxmax(axis=1).apply(lambda x: int(x.split('_')[1]))\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Create an instance of SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "\n",
        "# Resample the training data using SMOTE\n",
        "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_series)\n",
        "\n",
        "# Describe info about train and test set\n",
        "print(\"Number of transactions in X_train dataset: \", X_train_resampled.shape)\n",
        "print(\"Number of transactions in y_train dataset: \", y_train_resampled.shape)\n",
        "print(\"Number of transactions in X_test dataset: \", X_test.shape)\n",
        "print(\"Number of transactions in y_test dataset: \", y_test.shape)"
      ],
      "metadata": {
        "id": "LAJGaKBArWI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:43:44.970556Z",
          "iopub.status.busy": "2024-06-03T03:43:44.970246Z",
          "iopub.status.idle": "2024-06-03T03:43:45.000894Z",
          "shell.execute_reply": "2024-06-03T03:43:44.999927Z",
          "shell.execute_reply.started": "2024-06-03T03:43:44.970530Z"
        },
        "trusted": true,
        "id": "7BmloFI2LtCE"
      },
      "outputs": [],
      "source": [
        "#Converting the target variable train data shape that of test data shape\n",
        "\n",
        "# Extract the target variable\n",
        "y = y_train_resampled.values.reshape(-1, 1)\n",
        "\n",
        "# Initialize the OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Fit and transform the target variable\n",
        "y_one_hot = encoder.fit_transform(y)\n",
        "\n",
        "# Convert y_train_resampled_one_hot back to DataFrame for consistency\n",
        "y_train_resampled_df = pd.DataFrame(y_one_hot, columns=[f'class_{int(i)}' for i in range(y_one_hot.shape[1])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:43:45.002485Z",
          "iopub.status.busy": "2024-06-03T03:43:45.002183Z",
          "iopub.status.idle": "2024-06-03T03:43:45.190995Z",
          "shell.execute_reply": "2024-06-03T03:43:45.189692Z",
          "shell.execute_reply.started": "2024-06-03T03:43:45.002459Z"
        },
        "id": "nia0uhiMTwZo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Chart - 1 visualization code\n",
        "# Dependant Column Value Counts\n",
        "print(y_train_resampled_df.value_counts())\n",
        "print(\" \")\n",
        "# Dependant Variable Column Visualization\n",
        "y_train_resampled_df.value_counts().plot(kind='pie',\n",
        "                              figsize=(15,6),\n",
        "                               labels=['1','2','3','4','5']\n",
        "\n",
        "\n",
        "                              )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIqpNgepFxVj"
      },
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbet1HwdGDTz"
      },
      "source": [
        "I have used SMOTE (Synthetic Minority Over-sampling technique) for balanced the 85:15 dataset.\n",
        "\n",
        "SMOTE is a technique in machine learning for dealing with issues that arise when working with an unbalanced data set. In practice, unbalanced data sets are common and most ML algorithms are highly prone to unbalanced data so we need to improve their performance by using techniques like SMOTE.\n",
        "\n",
        "To address this disparity, balancing schemes that augment the data to make it more balanced before training the classifier were proposed. Oversampling the minority class by duplicating minority samples or undersampling the majority class is the simplest balancing method.\n",
        "\n",
        "The idea of incorporating synthetic minority samples into tabular data was first proposed in SMOTE, where synthetic minority samples are generated by interpolating pairs of original minority points.\n",
        "\n",
        "SMOTE is a data augmentation algorithm that creates synthetic data points from raw data. SMOTE can be thought of as a more sophisticated version of oversampling or a specific data augmentation algorithm.\n",
        "\n",
        "SMOTE has the advantage of not creating duplicate data points, but rather synthetic data points that differ slightly from the original data points. SMOTE is a superior oversampling option.\n",
        "\n",
        "That's why for lots of advantages, I have used SMOTE technique for balancinmg the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:43:45.194161Z",
          "iopub.status.busy": "2024-06-03T03:43:45.192917Z",
          "iopub.status.idle": "2024-06-03T03:43:45.200689Z",
          "shell.execute_reply": "2024-06-03T03:43:45.199437Z",
          "shell.execute_reply.started": "2024-06-03T03:43:45.194115Z"
        },
        "trusted": true,
        "id": "I1LViMXjLtCG"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Further splitting the training data into training and validation sets (70:15:15 ratio)\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train_resampled, y_train_resampled_df, test_size=0.2, random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:43:45.203117Z",
          "iopub.status.busy": "2024-06-03T03:43:45.202406Z",
          "iopub.status.idle": "2024-06-03T03:43:45.214383Z",
          "shell.execute_reply": "2024-06-03T03:43:45.212721Z",
          "shell.execute_reply.started": "2024-06-03T03:43:45.203074Z"
        },
        "trusted": true,
        "id": "1Jh7EC-MLtCG"
      },
      "outputs": [],
      "source": [
        "# Describe info about train and test set\n",
        "print(\"Number of transactions in X_train dataset: \", X_train_resampled.shape)\n",
        "print(\"Number of transactions in y_train dataset: \", y_train_resampled_df.shape)\n",
        "print(\"Number of transactions in X_test dataset: \", X_test.shape)\n",
        "print(\"Number of transactions in y_test dataset: \", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCC591jGiD4"
      },
      "source": [
        "## ***7. ML Model Implementation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CN3TwqAUlX6"
      },
      "source": [
        "### DL Model - 1 - **Deep Learning ANN Classification Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vZpizgSUzRm"
      },
      "source": [
        "### **Step 1: Install Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "id": "PgbxlvSG-mjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:44:01.123435Z",
          "iopub.status.busy": "2024-06-03T03:44:01.123105Z",
          "iopub.status.idle": "2024-06-03T03:44:20.263148Z",
          "shell.execute_reply": "2024-06-03T03:44:20.261945Z",
          "shell.execute_reply.started": "2024-06-03T03:44:01.123407Z"
        },
        "id": "8wZsFm5OfgKp",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install scikeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:44:20.267263Z",
          "iopub.status.busy": "2024-06-03T03:44:20.266927Z",
          "iopub.status.idle": "2024-06-03T03:44:37.878250Z",
          "shell.execute_reply": "2024-06-03T03:44:37.877309Z",
          "shell.execute_reply.started": "2024-06-03T03:44:20.267233Z"
        },
        "id": "p564joBMXm1M",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAElNMhkU5LU"
      },
      "source": [
        "### **Step 2: Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:44:37.880849Z",
          "iopub.status.busy": "2024-06-03T03:44:37.879693Z",
          "iopub.status.idle": "2024-06-03T03:44:37.912744Z",
          "shell.execute_reply": "2024-06-03T03:44:37.911764Z",
          "shell.execute_reply.started": "2024-06-03T03:44:37.880811Z"
        },
        "trusted": true,
        "id": "8hnxZdftLtCW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:44:37.914306Z",
          "iopub.status.busy": "2024-06-03T03:44:37.913945Z",
          "iopub.status.idle": "2024-06-03T03:44:37.927095Z",
          "shell.execute_reply": "2024-06-03T03:44:37.926276Z",
          "shell.execute_reply.started": "2024-06-03T03:44:37.914272Z"
        },
        "id": "2oj6MlYMU9bC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dj565HzLtCY"
      },
      "source": [
        "### **Step 3: Ensuring the target labels  in the correct format.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure target labels are numerical and feature arrays are float\n",
        "y_train_numerical = y_train_resampled_df.astype(int)\n",
        "y_test_numerical = y_test.astype(int)\n",
        "\n",
        "# Convert DataFrame to numpy array and ensure float32 type\n",
        "X_train_array = X_train_resampled.values.astype(np.float32)\n",
        "X_test_array = X_test.values.astype(np.float32)\n",
        "\n",
        "# Ensure target labels are numpy arrays\n",
        "y_train_array = np.array(y_train_numerical)\n",
        "y_test_array = np.array(y_test_numerical)"
      ],
      "metadata": {
        "id": "93-IhVmQr4tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:46:00.331957Z",
          "iopub.status.busy": "2024-06-03T03:46:00.331593Z",
          "iopub.status.idle": "2024-06-03T03:46:00.339383Z",
          "shell.execute_reply": "2024-06-03T03:46:00.338412Z",
          "shell.execute_reply.started": "2024-06-03T03:46:00.331932Z"
        },
        "id": "bqgSNNo0ZxVE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Get input dimensions\n",
        "input_dim = X_train.shape[1]\n",
        "num_classes = len(np.unique(y))\n",
        "input_dim ,num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd2Wi_N-ZQxx"
      },
      "source": [
        "### **Step 4: Define the ANN Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th7UBqx8LtCc"
      },
      "source": [
        " **Adding Learning Rate Scheduler**\n",
        "\n",
        "First, you need to define a learning rate scheduler function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:46:00.340778Z",
          "iopub.status.busy": "2024-06-03T03:46:00.340490Z",
          "iopub.status.idle": "2024-06-03T03:46:00.354051Z",
          "shell.execute_reply": "2024-06-03T03:46:00.353284Z",
          "shell.execute_reply.started": "2024-06-03T03:46:00.340756Z"
        },
        "trusted": true,
        "id": "ou4VIUWzLtCd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:46:00.355544Z",
          "iopub.status.busy": "2024-06-03T03:46:00.355275Z",
          "iopub.status.idle": "2024-06-03T03:46:01.558640Z",
          "shell.execute_reply": "2024-06-03T03:46:01.557802Z",
          "shell.execute_reply.started": "2024-06-03T03:46:00.355522Z"
        },
        "trusted": true,
        "id": "rt2b1KJPLtCe"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "\n",
        "# Dropout rate\n",
        "dropout_rate = 0.5\n",
        "\n",
        "# Define the neural network model with BatchNormalization and Dropout layers\n",
        "neural_classifier = Sequential(\n",
        "    [\n",
        "        Dense(128, activation=\"relu\", kernel_regularizer=l2(),input_dim=X_train.shape[1]),\n",
        "        BatchNormalization(),\n",
        "        Dropout(dropout_rate),\n",
        "\n",
        "        Dense(96, activation=\"relu\", kernel_regularizer=l2()),\n",
        "        BatchNormalization(),\n",
        "        Dropout(dropout_rate),\n",
        "\n",
        "        Dense(64, activation=\"relu\", kernel_regularizer=l2()),\n",
        "        BatchNormalization(),\n",
        "        Dropout(dropout_rate),\n",
        "\n",
        "        Dense(32, activation=\"relu\", kernel_regularizer=l2()),\n",
        "        BatchNormalization(),\n",
        "        Dropout(dropout_rate),\n",
        "\n",
        "        Dense(num_classes, activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Print the model summary\n",
        "neural_classifier.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI1MSTt4aLcD"
      },
      "source": [
        "### **Step 5: Define and Initialize the Keras Classifier model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:46:01.560028Z",
          "iopub.status.busy": "2024-06-03T03:46:01.559750Z",
          "iopub.status.idle": "2024-06-03T03:46:01.564991Z",
          "shell.execute_reply": "2024-06-03T03:46:01.564192Z",
          "shell.execute_reply.started": "2024-06-03T03:46:01.560004Z"
        },
        "trusted": true,
        "id": "Z211i3MILtCf"
      },
      "outputs": [],
      "source": [
        "### Initialize Model\n",
        "\n",
        "scikeras_classifier = KerasClassifier(model=neural_classifier,\n",
        "                                    optimizer=\"adam\",\n",
        "                                    loss=keras.losses.categorical_crossentropy,\n",
        "                                    batch_size=4000,\n",
        "                                    epochs=30,\n",
        "                                    metrics=['accuracy'],\n",
        "                                    random_state=42,\n",
        "                                    warm_start=True\n",
        "                          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCZZjZmcLtCf"
      },
      "source": [
        "### **Step 6: Initialize StratifiedKFold Cross Validation (no. of folds=3)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:46:01.566635Z",
          "iopub.status.busy": "2024-06-03T03:46:01.566175Z",
          "iopub.status.idle": "2024-06-03T03:46:01.575879Z",
          "shell.execute_reply": "2024-06-03T03:46:01.575019Z",
          "shell.execute_reply.started": "2024-06-03T03:46:01.566605Z"
        },
        "trusted": true,
        "id": "hdDi6kKRLtCf"
      },
      "outputs": [],
      "source": [
        "# Define number of folds\n",
        "n_folds = 3\n",
        "\n",
        "# Initialize StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEHFNq7hLtCg"
      },
      "source": [
        "### **Step 7: Performing 3-fold cross validation and training the ANN deep learning model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:46:01.577398Z",
          "iopub.status.busy": "2024-06-03T03:46:01.577026Z",
          "iopub.status.idle": "2024-06-03T03:53:52.772585Z",
          "shell.execute_reply": "2024-06-03T03:53:52.771621Z",
          "shell.execute_reply.started": "2024-06-03T03:46:01.577370Z"
        },
        "trusted": true,
        "id": "r-PcewtrLtCg"
      },
      "outputs": [],
      "source": [
        "# Lists to store train and test accuracies\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "# Lists to store train and test accuracies for visualization\n",
        "history_list = []\n",
        "\n",
        "# Perform 3-fold cross-validation\n",
        "for train_index, test_index in skf.split(X_train_array, np.argmax(y_train_array, axis=1)):\n",
        "    X_train_fold, X_test_fold = X_train_array[train_index], X_train_array[test_index]\n",
        "    y_train_fold, y_test_fold = y_train_array[train_index], y_train_array[test_index]\n",
        "\n",
        "    # Define EarlyStopping callback\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    # Define LearningRateScheduler callback\n",
        "    lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "    # Fit the model with early stopping and learning rate scheduler\n",
        "    scikeras_classifier.fit(X_train_fold, y_train_fold,\n",
        "              validation_data=(X_test_fold, y_test_fold),\n",
        "              callbacks=[early_stopping, lr_scheduler],\n",
        "              verbose=1)\n",
        "\n",
        "    # Append the history for visualization later\n",
        "    history_list.append(scikeras_classifier.history_)\n",
        "\n",
        "    # Evaluate the model on train data\n",
        "    train_accuracy = scikeras_classifier.score(X_train_fold, y_train_fold)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Evaluate the model on test data\n",
        "    test_accuracy = scikeras_classifier.score(X_test_fold, y_test_fold)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    # Train metric\n",
        "    y_pred_tr = scikeras_classifier.predict(X_train_fold)\n",
        "    y_pred_classes_tr = np.argmax(y_pred_tr, axis=1)\n",
        "    y_test_classes_tr = np.argmax(y_train_fold, axis=1)\n",
        "\n",
        "    # Test Metric\n",
        "    y_pred = scikeras_classifier.predict(X_test_fold)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_test_classes = np.argmax(y_test_fold, axis=1)\n",
        "\n",
        "    print(\"Train Accuracy:\", accuracy_score(y_test_classes_tr, y_pred_classes_tr))\n",
        "    print(\"Test Accuracy:\", accuracy_score(y_test_classes, y_pred_classes))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test_classes, y_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean train and test accuracies\n",
        "mean_train_accuracy = np.mean(train_accuracies)\n",
        "mean_test_accuracy = np.mean(test_accuracies)\n",
        "\n",
        "# Evaluation Metrics\n",
        "print(\"Mean Train Accuracy:\", mean_train_accuracy)\n",
        "print(\"Mean Test Accuracy:\", mean_test_accuracy)"
      ],
      "metadata": {
        "id": "vwkfJu_MuZKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKSMjOOZLtCh"
      },
      "source": [
        "### **Step-8 Grid Search Model Hyperparameters**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn imblearn tensorflow scikeras # Add any other ML libraries you're using (e.g., xgboost, lightgbm if applicable)"
      ],
      "metadata": {
        "id": "DvwjIy5owPRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn"
      ],
      "metadata": {
        "id": "vfGdeVMRbKLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T03:53:52.781777Z",
          "iopub.status.busy": "2024-06-03T03:53:52.781477Z",
          "iopub.status.idle": "2024-06-03T05:25:40.879832Z",
          "shell.execute_reply": "2024-06-03T05:25:40.878810Z",
          "shell.execute_reply.started": "2024-06-03T03:53:52.781753Z"
        },
        "trusted": true,
        "id": "dkrUNIqHLtCh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "params = {\n",
        "    \"optimizer__learning_rate\": [0.01, 0.001],\n",
        "    \"epochs\":[19,30],\n",
        "    \"batch_size\": [32,64,4000],\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(scikeras_classifier, params, scoring='accuracy')\n",
        "\n",
        "grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T05:25:40.881718Z",
          "iopub.status.busy": "2024-06-03T05:25:40.881252Z",
          "iopub.status.idle": "2024-06-03T05:25:40.887018Z",
          "shell.execute_reply": "2024-06-03T05:25:40.886155Z",
          "shell.execute_reply.started": "2024-06-03T05:25:40.881684Z"
        },
        "trusted": true,
        "id": "OzSx04PvLtCi"
      },
      "outputs": [],
      "source": [
        "print(\"Best Score  : {}\".format(grid.best_score_))\n",
        "print(\"Best Params : {}\".format(grid.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPqj45mELtCi"
      },
      "source": [
        "### **Step 9: Evaluating performance of ANN deep learning model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T05:25:40.888521Z",
          "iopub.status.busy": "2024-06-03T05:25:40.888236Z",
          "iopub.status.idle": "2024-06-03T05:25:58.395607Z",
          "shell.execute_reply": "2024-06-03T05:25:58.394618Z",
          "shell.execute_reply.started": "2024-06-03T05:25:40.888498Z"
        },
        "trusted": true,
        "id": "BF4X-n3ILtCi"
      },
      "outputs": [],
      "source": [
        "### Evaluate Model\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "print(\"Train Accuracy : {}\".format(accuracy_score(y_train, grid.predict(X_train))))\n",
        "print(\"Test  Accuracy : {}\".format(accuracy_score(y_test, grid.predict(X_test))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijopK3EXLtCj"
      },
      "source": [
        "### **Step 10: Visualization the performance of ANN deep learning model**\n",
        "Analyze the model's predictions to identify trends, patterns, and areas for service improvement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwNzhmQULtCj"
      },
      "source": [
        "#### **ROC AUC Curve**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T05:25:58.397889Z",
          "iopub.status.busy": "2024-06-03T05:25:58.397146Z",
          "iopub.status.idle": "2024-06-03T05:25:58.788958Z",
          "shell.execute_reply": "2024-06-03T05:25:58.787981Z",
          "shell.execute_reply.started": "2024-06-03T05:25:58.397851Z"
        },
        "trusted": true,
        "id": "IJcVyeXFLtCk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "def plot_roc_curve(y_test, y_pred, num_classes):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i in range(num_classes):\n",
        "        fpr, tpr, _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2, label='Class %d (area = %0.2f)' % (i, roc_auc))\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Assuming `y_test_classes` and `y_pred` are the one-hot encoded true and predicted labels\n",
        "plot_roc_curve(y_test_fold, y_pred, num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTJJ_fkaLtCk"
      },
      "source": [
        "#### **Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T05:25:58.790447Z",
          "iopub.status.busy": "2024-06-03T05:25:58.790144Z",
          "iopub.status.idle": "2024-06-03T05:25:59.125442Z",
          "shell.execute_reply": "2024-06-03T05:25:59.124541Z",
          "shell.execute_reply.started": "2024-06-03T05:25:58.790421Z"
        },
        "trusted": true,
        "id": "S1XPyeI1LtCk"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_test, y_pred_classes, class_names):\n",
        "    cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred_classes)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Assuming `y_test_classes` and `y_pred_classes` are the true and predicted labels\n",
        "class_names = ['Class 1', 'Class 2', 'Class 3','Class 4','Class 5']  # Replace with your actual class names\n",
        "plot_confusion_matrix(y_test_fold, y_pred_classes, class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRfZgRd5LtCl"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH72QReLLtCl"
      },
      "source": [
        "#### **Classification Report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T05:25:59.127272Z",
          "iopub.status.busy": "2024-06-03T05:25:59.126893Z",
          "iopub.status.idle": "2024-06-03T05:25:59.162419Z",
          "shell.execute_reply": "2024-06-03T05:25:59.161587Z",
          "shell.execute_reply.started": "2024-06-03T05:25:59.127238Z"
        },
        "trusted": true,
        "id": "JvD-ffvzLtCl"
      },
      "outputs": [],
      "source": [
        "def print_classification_report(y_test, y_pred_classes, class_names):\n",
        "    class_names = ['Class 1', 'Class 2', 'Class 3','Class 4','Class 5']\n",
        "    report = classification_report(np.argmax(y_test, axis=1), y_pred_classes, target_names=class_names)\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Print classification report\n",
        "print_classification_report(y_test_fold, y_pred_classes, class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38KgGkpILtCm"
      },
      "source": [
        "Class-wise Performance:\n",
        "The precision, recall, and F1-score metrics for each class provide insights into the model's performance for individual classes.\n",
        "\n",
        "Notably:\n",
        "\n",
        "Class 1:\n",
        "\n",
        "Precision: 91%\n",
        "Recall: 66%\n",
        "F1-score: 76%\n",
        "Support: 13935\n",
        "The model demonstrates high precision but lower recall for Class 1, suggesting that while it correctly identifies most instances with Class 1, it may miss some relevant instances.\n",
        "\n",
        "Class 2:\n",
        "\n",
        "Precision: 99%\n",
        "Recall: 97%\n",
        "F1-score: 98%\n",
        "Support: 13935\n",
        "The model achieves excellent precision and recall for Class 2, indicating it is very effective in identifying instances with Class 2.\n",
        "\n",
        "Class 3:\n",
        "\n",
        "Precision: 98%\n",
        "Recall: 91%\n",
        "F1-score: 95%\n",
        "Support: 13935\n",
        "Similar to Class 2, the model shows high precision and recall for Class 3, reflecting its effectiveness in predicting instances with Class 3.\n",
        "\n",
        "Class 4:\n",
        "\n",
        "Precision: 83%\n",
        "Recall: 68%\n",
        "F1-score: 75%\n",
        "Support: 13936\n",
        "The model exhibits decent precision and recall for Class 4, indicating moderate performance in identifying instances with Class 4.\n",
        "\n",
        "Class 5:\n",
        "\n",
        "Precision: 64%\n",
        "Recall: 99%\n",
        "F1-score: 78%\n",
        "Support: 13935\n",
        "The model demonstrates relatively lower precision but higher recall for Class 5, implying that while it correctly identifies most instances with Class 5, it may also misclassify some instances from other classes as Class 5.\n",
        "\n",
        "Overall Performance:\n",
        "Accuracy: 84%\n",
        "Macro Average:\n",
        "Precision: 87%\n",
        "Recall: 84%\n",
        "F1-score: 84%\n",
        "Weighted Average:\n",
        "Precision: 87%\n",
        "Recall: 84%\n",
        "F1-score: 84%\n",
        "The model's overall accuracy is 84%, with macro and weighted averages indicating consistent performance across most classes, though with some variability in precision and recall.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgzYm8AnLtCm"
      },
      "source": [
        "### **Training and Validation Accuracy Plot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T05:25:59.163798Z",
          "iopub.status.busy": "2024-06-03T05:25:59.163504Z",
          "iopub.status.idle": "2024-06-03T05:25:59.489877Z",
          "shell.execute_reply": "2024-06-03T05:25:59.488963Z",
          "shell.execute_reply.started": "2024-06-03T05:25:59.163773Z"
        },
        "trusted": true,
        "id": "VERQMKKJLtCn"
      },
      "outputs": [],
      "source": [
        "# Assuming history_list contains the training history for each fold\n",
        "mean_train_accuracy = []\n",
        "mean_val_accuracy = []\n",
        "\n",
        "# Calculate mean accuracy for each epoch\n",
        "for epoch in range(30):  # Assuming max 30 epochs\n",
        "    epoch_train_acc = np.mean([history['accuracy'][epoch] for history in history_list if epoch < len(history['accuracy'])])\n",
        "    epoch_val_acc = np.mean([history['val_accuracy'][epoch] for history in history_list if epoch < len(history['val_accuracy'])])\n",
        "    mean_train_accuracy.append(epoch_train_acc)\n",
        "    mean_val_accuracy.append(epoch_val_acc)\n",
        "\n",
        "# Plot mean train and validation accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(mean_train_accuracy, label='Mean Train Accuracy')\n",
        "plt.plot(mean_val_accuracy, label='Mean Validation Accuracy')\n",
        "plt.title('Mean Training and Validation Accuracy Across Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLTSyMe3_MXH"
      },
      "source": [
        "# **Data Preprocessing Blog**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYNmUe2H_pPX"
      },
      "source": [
        "https://medium.com/almabetter/data-preprocessing-ea09fac6a7f7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**\n",
        "\n",
        "Data Overview: The dataset comprises records from the e-commerce industry, focusing on customer service interactions and CSAT scores. It contains 85907 rows and 20 columns, with missing values in several columns such as Customer_city, Product_category, and item_price.\n",
        "\n",
        "CSAT Importance: CSAT is a crucial KPI for e-commerce businesses, reflecting customer satisfaction with products, services, and overall experience. Understanding CSAT is vital for driving business success.\n",
        "\n",
        "Variable Insights: The dataset captures detailed information about customer service interactions, including customer feedback, order details, agent information, and timestamps. Understanding these variables provides valuable insights into customer satisfaction drivers.\n",
        "\n",
        "Exploratory Data Analysis (EDA): EDA aims to gain insights into customer satisfaction patterns. Factors like response time, product category, channel effectiveness, agent tenure, shift timings, and customer feedback are analyzed to uncover potential reasons for CSAT scores.\n",
        "\n",
        "Response Time Impact: Longer response times correlate with lower CSAT scores, indicating the need for quicker response mechanisms to improve customer satisfaction.\n",
        "Product Category Analysis: Certain product categories consistently yield lower CSAT scores, suggesting issues with these products or their support processes that need addressing.\n",
        "\n",
        "Agent Experience: Agents with longer tenures tend to receive higher CSAT scores, highlighting the importance of experience in delivering satisfactory customer service.\n",
        "\n",
        "Shift Timings Influence: CSAT scores vary based on agent shift timings, indicating potential workload or resource issues during specific shifts that need attention.\n",
        "\n",
        "\n",
        "CSAT Score vs. Item Price: A negative correlation between item price and CSAT score suggests that higher-priced items are associated with lower customer satisfaction. This finding underscores the importance of pricing strategies in maintaining high CSAT scores.\n",
        "\n",
        "Data-driven Decision Making: Leveraging data insights from EDA enables data-driven decision-making processes, empowering businesses to implement strategies that positively impact CSAT scores and drive long-term success.\n",
        "\n",
        "\n",
        "Response Time and CSAT Score: Statistical analysis indicates that a mean response time of less than 2 hours is significantly correlated with higher CSAT scores. This underscores the importance of prompt response times in enhancing customer satisfaction.\n",
        "\n",
        "Price Impact on CSAT Score: Hypothesis testing suggests that items priced above a certain threshold do not significantly affect CSAT scores to go below 3. This finding provides insights into pricing strategies and their impact on customer satisfaction.\n",
        "\n",
        "\n",
        "Data Preprocessing Techniques: Various techniques such as handling missing values, outlier detection, and categorical encoding were employed to ensure data quality and prepare it for analysis.\n",
        "\n",
        "Feature Engineering: Feature manipulation, selection, and transformation techniques were utilized to create informative features and enhance the predictive power of the model.\n",
        "\n",
        "Data Splitting for Training: A 70:30 ratio was chosen for data splitting to balance the trade-off between training and testing data size, considering the small training dataset.\n",
        "\n",
        "Handling Imbalance in Target Variable: The Synthetic Minority Over-sampling Technique (SMOTE) was applied to address the imbalanced class distribution, ensuring robust model training.\n",
        "\n",
        "Deep Learning Model Development: The development of a deep learning model using a neural network architecture, wrapped into a KerasClassifier, demonstrated promising performance in predicting CSAT scores, with an overall accuracy of approximately 85%.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIfDvo9L0UH2"
      },
      "source": [
        "### ***Hurrah! You have successfully completed your Deep Learning Capstone Project !!!***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T05:25:59.491452Z",
          "iopub.status.busy": "2024-06-03T05:25:59.491091Z",
          "iopub.status.idle": "2024-06-03T05:25:59.569954Z",
          "shell.execute_reply": "2024-06-03T05:25:59.568940Z",
          "shell.execute_reply.started": "2024-06-03T05:25:59.491421Z"
        },
        "trusted": true,
        "id": "3F7kjfMcLtCo"
      },
      "outputs": [],
      "source": [
        "scikeras_classifier.model_.save(\"csat_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzK6mO6uLtCp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "ILM16xV1PD8m",
        "bqVZBxrvPD8n",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "ZwW2pl1O3WwT",
        "NXm0OV-S9E2g",
        "Q5pG0ENk5O63",
        "M0QVFX0B8C8x",
        "jNouVC-U62KI",
        "0NNA-0cy-dcQ",
        "j3CETLqIAO6f",
        "4YbDiZh7A-_O",
        "EzCh2lklBEsf",
        "kmPcFk5iFH6C",
        "XYy5gcchKnaH",
        "h7gi-LRXLeZl",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "xJivPyE8q_2k",
        "Of3PJYNbrGff",
        "jbkhcZqdrGfh",
        "riLp7y9brHca",
        "1Qw8mtL3rHcd",
        "I3aNiIh9fKqZ",
        "hTF1e9PwfKqa",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "jLrtcv83OEmf",
        "DADo_qtwOEmg",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "pEMng2IbBLp7",
        "TNVZ9zx19K6k",
        "A1tXasLFv6Dt",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "OeJFEK0N496M",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "peAK6Cc_HQeo",
        "khncImPpHcol",
        "wTe8K5rdYGV1",
        "yyzM232tatvC",
        "OMC09DFCbrEm",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 5058629,
          "sourceId": 8481205,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}